
  

# 1. Оршил

  

Сүүлийн жилүүдэд **Natural Language Processing (NLP)** буюу байгалийн хэлний боловсруулалт нь хиймэл оюун ухааны хамгийн эрчимтэй хөгжиж буй салбаруудын нэг болж байна. NLP нь хүний бичвэр, яриаг компьютероор ойлгуулах, ангилах, утга гаргах зорилготой бөгөөд мэдээллийн олборлолт, санал бодлын шинжилгээ (*sentiment analysis*), чатбот, хайлтын систем зэрэг олон практик хэрэглээнд өргөн ашиглагдаж байна.

  

Энэхүү судалгааны ажлын хүрээнд бид **sentiment analysis** асуудлыг сонгон авч, түгээмэл ашиглагддаг нэгэн *dataset* дээр уламжлалт болон гүн сургалтын аргуудыг харьцуулан судаллаа. Тайлангийн үндсэн зорилгууд нь дараах байдалтай байна:

  

- Dataset-ийн онцлогийг судлах

- Өмнөх судалгаануудын арга барилыг нэгтгэн дүгнэх

- Embedding болон модель сонголтын нөлөөг үнэлэх

- Үр дүнг стандарт үнэлгээний хэмжүүрүүдээр харьцуулах

  

# 2. Ашигласан өгөгдлийн сан (Dataset)-ийн танилцуулга

  

## 2.1 Dataset-ийн ерөнхий мэдээлэл

  

Энэхүү судалгаанд **IMDB Movie Reviews Dataset**-ийг ашигласан. Уг dataset нь киноны хэрэглэгчдийн бичсэн сэтгэгдлүүд дээр суурилсан бөгөөд **эерэг (positive)** болон **сөрөг (negative)** гэсэн хоёр ангилалтай.

  

-  **Зорилго:** Sentiment analysis

-  **Өгөгдлийн төрөл:** Текст

-  **Ангиллын тоо:** 2 (Positive, Negative)

-  **Нийт бичвэрийн тоо:** 50,000

-  **Сургалтын өгөгдөл:** 25,000

-  **Тестийн өгөгдөл:** 25,000

  

## 2.2 Dataset-ийн эх сурвалж

  

IMDB Movie Reviews dataset-ийг дараах албан ёсны эх сурвалжаас татан авсан.

  

- https://ai.stanford.edu/~amaas/data/sentiment/

  

## 2.3 Dataset ашигласан байдал

  

Энэхүү dataset-ийг дараах зорилгоор олон удаагийн туршилт хийж ашигласан. Үүнд:

  

- Текстийг цэвэрлэх (*tokenization, stopword removal*)

-  **TF-IDF**, **Word2Vec** embedding ашиглах

-  **Deep Learning** модель (LSTM, BERT) сургах

- Үр дүнг харьцуулан дүгнэх

  

Dataset-ийг **train/test** хэлбэрээр стандарт байдлаар ашигласан ба нэмэлтээр **cross-validation** туршилт хийсэн.

  

Энэхүү судалгаанд IMDB Movie Reviews dataset-ийг нийт **хоёр үндсэн туршилтад** ашигласан.

  

Эхний туршилтад уламжлалт машин сургалтын аргуудын суурь гүйцэтгэлийг тодорхойлох зорилгоор **TF-IDF embedding** болон **Logistic Regression** загварыг ашигласан. Энэхүү туршилт нь **baseline** загварын үр дүнг тогтоож, дараагийн гүн сургалтын загвартай харьцуулах үндэс болсон.

  

Хоёр дахь туршилтад **contextual embedding**-д суурилсан гүн сургалтын арга болох **BERT** загварыг ашиглан sentiment analysis даалгаварт **fine-tuning** хийсэн. Энэ туршилтын зорилго нь өгүүлбэрийн **контекстийг харгалзан үздэг embedding** ашиглах нь ангиллын гүйцэтгэлд хэрхэн нөлөөлж байгааг судлах явдал байв.

  

Туршилт бүрт dataset-ийг стандарт **train/test** хуваалтаар ашиглаж, загваруудын үр дүнг ижил нөхцөлд харьцуулан үнэлсэн.

# 3. Dataset-тэй холбоотой судалгааны ажлууд (Papers)

  

IMDB Movie Reviews Dataset-ийг ашигласан **10 судалгааны өгүүллийг** доор жагсаав.

  

1.  **Maas et al. (2011)** – *Learning Word Vectors for Sentiment Analysis*

https://ai.stanford.edu/~amaas/papers/wvSent_acl2011.pdf

  

2.  **Pang & Lee (2008)** – *Opinion Mining and Sentiment Analysis*

https://www.cs.cornell.edu/home/llee/omsa/omsa.pdf

  

3.  **Kim, Y. (2014)** – *Convolutional Neural Networks for Sentence Classification*

https://arxiv.org/abs/1408.5882

  

4.  **Zhang et al. (2015)** – *Character-level Convolutional Networks for Text Classification*

https://arxiv.org/abs/1509.01626

  

5.  **Johnson & Zhang (2017)** – *Deep Pyramid Convolutional Neural Networks*

https://arxiv.org/abs/1707.09055

  

6.  **Devlin et al. (2019)** – *BERT: Pre-training of Deep Bidirectional Transformers*

https://arxiv.org/abs/1810.04805

  

7.  **Howard & Ruder (2018)** – *Universal Language Model Fine-tuning (ULMFiT)*

https://arxiv.org/abs/1801.06146

  

8.  **Dai & Le (2015)** – *Semi-supervised Sequence Learning*

https://arxiv.org/abs/1511.01432

  

9.  **Radford et al. (2018)** – *Improving Language Understanding by Generative Pre-training*

https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf

  

10.  **Peters et al. (2018)** – *Deep Contextualized Word Representations (ELMo)*

https://arxiv.org/abs/1802.05365

  
  

# 4. Судалгаануудад ашигласан аргуудын тойм

  

## 4.1 Ашигласан аргууд

  

Судалгаануудад дараах уламжлалт болон гүн сургалтын аргууд өргөн ашиглагдсан.

  

-  **TF-IDF + Logistic Regression**

-  **Word2Vec + CNN / LSTM**

-  **Pre-trained embedding** (GloVe, Word2Vec)

-  **Transformer-based models** (BERT, GPT)

  

## 4.2 Түгээмэл hyperparameter-ууд

  

Судалгаануудад нийтлэг ашиглагддаг hyperparameter-ууд нь дараах байдалтай байна.

  

-  **Embedding dimension:** 100, 200, 300

-  **Learning rate:** 1e-5 – 1e-3

# 5. Dataset-тэй холбоотой судалгааны ажлуудын дэлгэрэнгүй тойм (Related Work)

  


### Үр дүн ба дүгнэлт

Maas et al. (2011) судалгааны үр дүнгээс харахад **distributional word representation** ашигласан загварууд нь уламжлалт **bag-of-words** болон *n-gram* дээр суурилсан аргуудаас **тогтвортойгоор өндөр гүйцэтгэл** үзүүлсэн. Ялангуяа үгний embedding-ийн хэмжээг **50 болон 100** байхаар тохируулсан үед загварын accuracy **88–90%** хүрч, тухайн үеийн sentiment analysis судалгаанд **state-of-the-art** үр дүнг тогтоосон.

Судалгаанд **semi-supervised learning** ашигласнаар шошгогүй өгөгдлөөс үгсийн семантик болон сэтгэл хөдлөлийн мэдээллийг үр ашигтай сурч чадсан нь ангилалтын чанарт шууд эерэг нөлөө үзүүлсэн. Үүний үр дүнд өгөгдлийн *sparsity* болон *dimensionality*-ийн асуудлыг бууруулж, үгс хоорондын утгын ойролцоо байдлыг илүү сайн хадгалж чадсан.

Дүгнэж хэлбэл, энэхүү судалгаа нь **word embedding + supervised classifier** хослол нь sentiment analysis-д өндөр үр ашигтай болохыг баталж, улмаар **Word2Vec, GloVe, FastText, BERT** зэрэг дараагийн embedding болон гүн сургалтын загваруудын хөгжлийн суурь болсон. Иймд Maas et al. (2011) ажлыг NLP салбарт **embedding-д суурилсан sentiment analysis-ийн эхлэл** гэж үзэх бүрэн үндэслэлтэй юм.

  

---

  

## 5.2 Pang & Lee (2008) – *Opinion Mining and Sentiment Analysis*

Pang болон Lee (2008) нарын энэхүү өгүүлэл нь sentiment analysis салбарын **онолын суурийг тавьсан тойм судалгаа** бөгөөд тухайн үе хүртэл хийгдсэн текстийн сэтгэл хөдлөлийн шинжилгээний аргуудыг системтэйгээр нэгтгэн дүгнэсэн анхны чухал ажлуудын нэг юм. Тэд киноны сэтгэгдэл зэрэг бодит текстэн өгөгдөл дээр тулгуурлан sentiment analysis-ийг **текст ангиллын (text classification)** асуудал гэж тодорхойлсон.

### Ашигласан арга

Судалгаанд **Naive Bayes**, **Support Vector Machine (SVM)** зэрэг уламжлалт машин сургалтын аргуудыг өргөн ашигласан. Эдгээр аргууд нь текстийг тоон хэлбэрт шилжүүлэхдээ **bag-of-words** болон **TF-IDF** representation ашиглаж, үгсийн давтамж болон ялгах чадварыг гол шинж тэмдэг (feature) болгон авч үзсэн. Feature-ийн хэмжээг ихэвчлэн **5,000–20,000** орчимд тохируулж, ангиллын гүйцэтгэлийг сайжруулах зорилгоор feature selection аргачлалуудыг мөн авч үзсэн.

### Үр дүн ба дүгнэлт

Pang болон Lee (2008) нарын дүгнэлтээр **SVM** нь Naive Bayes-тай харьцуулахад ихэнх тохиолдолд **өндөр accuracy болон илүү тогтвортой үр дүн** үзүүлсэн боловч аль аль арга нь sentiment analysis-д үр ашигтай хэрэгжих боломжтойг харуулсан. Гэсэн хэдий ч эдгээр уламжлалт аргууд нь үгсийн **семантик утга**, өгүүлбэрийн бүтэц, контекст мэдээллийг бүрэн илэрхийлж чаддаггүй сул талтай болохыг онцолсон.

Дүгнэж хэлбэл, энэхүү тойм судалгаа нь sentiment analysis-ийг **бие даасан судалгааны салбар** болгон тодорхойлж, уламжлалт машин сургалтын аргуудын давуу болон хязгаарлалтыг тодорхой харуулсан. Улмаар энэ ажил нь word embedding болон гүн сургалтын аргууд руу шилжих судалгааны чиг хандлагыг бий болгоход суурь нөлөө үзүүлсэн гэж үздэг.

  

---

  


## 5.3 Kim (2014) – *Convolutional Neural Networks for Sentence Classification*

Kim (2014)-ийн судалгаа нь **Convolutional Neural Networks (CNN)**-ийг өгүүлбэрийн түвшний текст ангилалд амжилттай ашигласан анхны гүн сургалтын ажлуудын нэг юм. Энэхүү судалгаа нь NLP-д гүн сургалтын аргуудыг хэрэглэх боломжийг бодит үр дүнгээр баталсан чухал суурь ажилд тооцогддог.

### Ашигласан арга

Судалгаанд **IMDB Movie Reviews dataset**-ийг ашиглаж, өгүүлбэр болон баримт бичгийн түвшний ангиллыг CNN архитектураар гүйцэтгэсэн. Оролтын үе шатанд **pre-trained Word2Vec болон GloVe embedding**-үүдийг ашиглаж, эдгээр embedding-ийг CNN-ийн оролт болгон өгсөн. Embedding-ийн хэмжээг **300 dimension** байхаар тохируулсан.

CNN архитектур нь олон төрлийн *n-gram* шинжийг барих зорилгоор **3, 4, 5 хэмжээтэй convolution filter**-үүдийг ашигласан бөгөөд эдгээр filter-үүд нь өгүүлбэр доторх орон нутгийн хэв шинж (local features)-ийг автоматаар сурч авдаг. Үүний дараа **max-pooling** болон **fully connected layer** ашиглан ангилал хийсэн.

### Үр дүн ба дүгнэлт

Туршилтын үр дүнгээс харахад Kim (2014)-ийн санал болгосон CNN загвар нь **ойролцоогоор 90% accuracy** үзүүлж, тухайн үеийн уламжлалт машин сургалтын аргуудаас илүү гүйцэтгэлтэй болохыг харуулсан. Ялангуяа **pre-trained embedding** ашиглах нь сургалтын хурд болон ангиллын чанарт эерэг нөлөө үзүүлсэн.

Дүгнэж хэлбэл, энэхүү судалгаа нь **CNN архитектур текст өгөгдөлд үр дүнтэй** болохыг баталж, өгүүлбэрийн түвшний ангилал, sentiment analysis болон бусад NLP даалгавруудад гүн сургалтын аргууд өргөн хэрэглэгдэхэд чухал суурь болсон. Улмаар дараагийн олон судалгаанд CNN-д суурилсан загваруудын хөгжлийн эхлэл болсон гэж үздэг.


  

---

  


## 5.4 Zhang et al. (2015) – *Character-level Convolutional Networks*

Zhang et al. (2015) нарын судалгаа нь текстийг үгийн түвшинд бус, **character (үсэг) түвшинд** боловсруулах шинэ хандлагыг санал болгосон анхны чухал гүн сургалтын ажлуудын нэг юм. Энэхүү ажил нь хэл зүйн онцлог, үгийн алдаа, үгсийн сангаас үл хамаарах NLP загваруудыг хөгжүүлэх боломжийг харуулсан.

### Ашигласан арга

Судалгаанд **IMDB Movie Reviews** болон **Amazon Reviews** dataset-үүдийг ашиглаж, текстийг тогтмол урттай character дараалал болгон хувиргасан. Оролтын текстийн уртыг **1,014 тэмдэгт** байхаар тогтоож, түүнээс урт текстийг тайрч, богино текстийг padding хийсэн.

Загварын хувьд **олон convolution давхаргатай гүн CNN архитектур** ашигласан бөгөөд эдгээр convolution давхаргууд нь character түвшний хэв шинж, морфологи бүтэц болон орон нутгийн дарааллын мэдээллийг автоматаар сурч авдаг. Үүний дараа pooling болон fully connected давхаргуудыг ашиглан ангилал хийсэн.

### Үр дүн ба дүгнэлт

Туршилтын үр дүнгээс харахад character-level CNN загвар нь **88–92% accuracy** хүрч, үгэнд суурилсан уламжлалт аргуудаас дутахгүй гүйцэтгэл үзүүлсэн. Ялангуяа үгийн алдаа, бичгийн хэв маягийн ялгаа, хэлний онцлог өөрчлөлтөд **илүү тэсвэртэй** болох нь нотлогдсон.

Дүгнэж хэлбэл, энэхүү судалгаа нь **character-level representation** нь NLP-д үр ашигтай байж болохыг баталж, хэлнээс үл хамаарах (language-agnostic) загварууд, мөн social media зэрэг алдаатай, албан бус текст боловсруулах дараагийн судалгаанд чухал суурь болсон гэж үздэг.


  

---

  


## 5.5 Johnson & Zhang (2017) – *Deep Pyramid Convolutional Neural Networks*

Johnson болон Zhang (2017) нарын судалгаа нь **Convolutional Neural Networks (CNN)** архитектурыг илүү **гүн (deep)** болгох замаар текст ангиллын гүйцэтгэлийг сайжруулах боломжийг харуулсан чухал ажил юм. Энэхүү судалгаанд CNN загваруудыг компьютер хараанд ашигладаг гүн архитектуртай төстэй байдлаар текст өгөгдөлд амжилттай хэрэгжүүлсэн.

### Ашигласан арга

Судалгаанд **IMDB Movie Reviews** болон **Yelp Reviews** dataset-үүдийг ашиглаж, **Deep Pyramid Convolutional Neural Network (DPCNN)** архитектурыг санал болгосон. Оролтын үе шатанд **300 dimension бүхий word embedding** ашигласан.

DPCNN загвар нь convolution болон pooling давхаргуудыг шаталсан (pyramid) байдлаар зохион байгуулж, давхарга ахих тусам текстийн төлөөллийг илүү товч бөгөөд өндөр түвшний шинж болгон шахдаг. Загварын гүнийг **10–15 давхарга** байхаар тохируулснаар урт текстийн алслагдсан хамаарлыг илүү үр дүнтэй барих боломж бүрдсэн.

### Үр дүн ба дүгнэлт

Туршилтын үр дүнгээс харахад Johnson & Zhang (2017)-ийн санал болгосон **DPCNN** загвар нь **ойролцоогоор 93% accuracy** хүрч, өмнөх CNN-д суурилсан аргуудаас илүү гүйцэтгэл үзүүлсэн. Мөн загварын гүнийг нэмэгдүүлэх нь overfitting-ийг хяналттайгаар багасгаж, том хэмжээний өгөгдөл дээр **масштаблах боломжтой** болохыг нотолсон.

Дүгнэж хэлбэл, энэхүү судалгаа нь **гүн CNN архитектур текст өгөгдөлд үр дүнтэй** хэрэгжих боломжтойг баталж, дараагийн олон текст ангилал болон sentiment analysis судалгаанд DPCNN загварыг суурь архитектур болгон ашиглахад чухал нөлөө үзүүлсэн.


  

---

  


## 5.6 Devlin et al. (2019) – *BERT*

Devlin et al. (2019)-ийн санал болгосон **BERT (Bidirectional Encoder Representations from Transformers)** загвар нь Transformer архитектурт суурилсан, **хоёр чиглэлтэй (bidirectional) контекст ойлголттой** embedding загвар юм. Энэхүү судалгаа нь өмнөх static embedding аргуудаас ялгаатайгаар үг бүрийн утгыг тухайн өгүүлбэрийн **бүхэл контекстээс хамааруулан** илэрхийлдэг шинэ хандлагыг NLP-д нэвтрүүлсэн.

### Ашигласан арга

BERT загварыг **Wikipedia** болон **BookCorpus** зэрэг том хэмжээний текстэн өгөгдөл дээр **unsupervised pre-training** аргаар сургаж, **Masked Language Model (MLM)** болон **Next Sentence Prediction (NSP)** зорилтуудыг ашигласан. Үүний дараа sentiment analysis зэрэг тодорхой даалгавруудад **fine-tuning** хийж ашигласан.

Энэхүү судалгаанд ашигласан **BERT-Base** загвар нь **12 Transformer encoder давхарга**, **768 hidden size**, **12 attention head**-тэй архитектуртай. IMDB Movie Reviews dataset дээр fine-tuning хийж, баримт бичгийн түвшний sentiment ангиллыг гүйцэтгэсэн.

### Үр дүн ба дүгнэлт

Туршилтын үр дүнгээс харахад BERT загвар нь sentiment analysis дээр **94–95% accuracy** хүрч, тухайн үеийн бүх уламжлалт болон CNN/RNN-д суурилсан загваруудыг **илт давсан гүйцэтгэл** үзүүлсэн. Contextual embedding ашигласнаар урт хугацааны хамаарал, өгүүлбэрийн утга, үгсийн олон утгыг илүү нарийвчлалтай илэрхийлж чадсан нь гол давуу тал болсон.

Дүгнэж хэлбэл, Devlin et al. (2019) судалгаа нь **contextual word representation**-ийг NLP-ийн **стандарт арга** болгон тогтоож, sentiment analysis төдийгүй асуулт-хариулт, текстийн ойлголт, нэр томьёо таних зэрэг олон даалгаварт Transformer-д суурилсан загварууд давамгайлах эхлэлийг тавьсан суурь ажил болсон юм.


  

---

  


## 5.7 Howard & Ruder (2018) – *ULMFiT*

Howard & Ruder (2018)-ийн санал болгосон **ULMFiT (Universal Language Model Fine-tuning)** загвар нь NLP салбарт **transfer learning**-ийг бодитоор амжилттай хэрэгжүүлсэн анхны чухал судалгаануудын нэг юм. Энэхүү ажил нь том хэмжээний корпус дээр сурсан хэлний загварыг тодорхой даалгаварт **үр ашигтайгаар дахин тохируулах** боломжийг харуулсан.

### Ашигласан арга

ULMFiT нь **AWD-LSTM** архитектурт суурилсан хэлний загварыг ашигласан бөгөөд энэхүү загвар нь **3 LSTM давхаргатай** бүтэцтэй. Загварыг эхлээд ерөнхий текстэн өгөгдөл дээр хэлний загварын зорилгоор сургаж, дараа нь **IMDB Movie Reviews dataset** дээр sentiment analysis хийх зорилгоор fine-tuning хийсэн.

Fine-tuning үе шатанд **discriminative fine-tuning**, **gradual unfreezing**, болон **slanted triangular learning rate schedule** зэрэг аргачлалуудыг ашигласан бөгөөд learning rate-ийг ойролцоогоор **1e-3** байхаар тохируулсан. Эдгээр стратеги нь overfitting-ийг бууруулж, жижиг хэмжээний шошготой өгөгдөл дээр ч өндөр гүйцэтгэл гаргахад чухал нөлөө үзүүлсэн.

### Үр дүн ба дүгнэлт

Туршилтын үр дүнгээс харахад ULMFiT загвар нь sentiment analysis дээр **ойролцоогоор 95% accuracy** хүрч, тухайн үеийн хамгийн өндөр гүйцэтгэлтэй аргуудын нэг болсон. Энэхүү үр дүн нь BERT-ээс өмнөх үед гүн сургалтын аргууд дундаас **state-of-the-art** түвшинд хүрсэн үзүүлэлт гэж үзэгддэг.

Дүгнэж хэлбэл, Howard & Ruder (2018) судалгаа нь **transfer learning NLP-д зайлшгүй хэрэгтэй** гэдгийг нотолж, улмаар Transformer-д суурилсан BERT, RoBERTa зэрэг загваруудын fine-tuning хандлагын суурийг тавьсан чухал ажил болсон юм.


  

---

  


## 5.8 Dai & Le (2015) – *Semi-supervised Sequence Learning*

Dai & Le (2015) нарын судалгаа нь шошготой өгөгдөл хязгаарлагдмал нөхцөлд **semi-supervised sequence learning** ашиглан текст ангиллын гүйцэтгэлийг сайжруулах боломжийг харуулсан чухал ажил юм. Энэхүү судалгаа нь дараалал өгөгдөлд суурилсан загваруудыг шошгогүй өгөгдөлтэй хослуулах шинэ хандлагыг санал болгосон.

### Ашигласан арга

Судалгаанд **IMDB Movie Reviews dataset**-ийг ашиглаж, текстийн дарааллыг загварчлах зорилгоор **Recurrent Neural Network (RNN)** болон **sequence autoencoder** архитектуруудыг хэрэглэсэн. Эхний шатанд autoencoder-ийг шошгогүй өгөгдөл дээр сургаж, өгөгдлийн ерөнхий дарааллын бүтэц болон хэл зүйн хэв шинжийг сурсан.

Үүний дараа сурсан жингүүдийг sentiment analysis даалгаварт **fine-tuning** хийж ашигласан. Загварын **hidden size-ийг 256**, сургалтын **epoch-ийн тоог ойролцоогоор 20** байхаар тохируулсан.

### Үр дүн ба дүгнэлт

Туршилтын үр дүнгээс харахад Dai & Le (2015)-ийн санал болгосон semi-supervised арга нь зөвхөн supervised сургалттай харьцуулахад sentiment analysis-ийн гүйцэтгэлийг **3–5%-иар нэмэгдүүлсэн**. Ялангуяа labeled өгөгдөл цөөн нөхцөлд энэхүү арга нь илүү их давуу талтай болохыг харуулсан.

Дүгнэж хэлбэл, энэхүү судалгаа нь **sequence-level pre-training** нь NLP-д үр ашигтай болохыг баталж, улмаар ULMFiT болон Transformer-д суурилсан pre-training + fine-tuning хандлагын хөгжлийн суурь болсон чухал ажилд тооцогддог.


  

---

  


## 5.9 Radford et al. (2018) – *GPT*

Radford et al. (2018)-ийн судалгаа нь **Transformer decoder** архитектурт суурилсан **generative pre-training** хандлагыг санал болгосон бөгөөд NLP салбарт урьдчилан сургах (pre-training) шинэ чиглэлийг нээсэн чухал ажил юм. Энэхүү загвар нь текстийг дарааллын дагуу үүсгэх (generation) чадварыг ашиглан хэлний ерөнхий мэдлэгийг сурч авдгаараа онцлогтой.

### Ашигласан арга

GPT загварыг том хэмжээний текстэн корпус дээр **unsupervised generative language modeling** зорилгоор урьдчилан сургаж, дараа нь тодорхой NLP даалгавруудад **fine-tuning** хийж ашигласан. Архитектурын хувьд **12 Transformer decoder давхаргатай**, **context length 512**-той загварыг ашигласан.

Sentiment analysis туршилтыг **IMDB Movie Reviews dataset** дээр гүйцэтгэж, pre-trained загварыг баримт бичгийн түвшний ангилалд fine-tuning хийсэн. Энэхүү арга нь нэг загварыг олон даалгаварт дасан зохицуулах боломжтойг харуулсан.

### Үр дүн ба дүгнэлт

Туршилтын үр дүнгээс харахад GPT загвар нь sentiment analysis дээр **92–94% accuracy** хүрч, тухайн үеийн CNN болон RNN-д суурилсан олон загваруудтай өрсөлдөхүйц гүйцэтгэл үзүүлсэн. Generative pre-training ашигласнаар хэлний урт хугацааны хамаарал, өгүүлбэрийн бүтцийг илүү сайн ойлгож чадсан нь гол давуу тал болсон.

Дүгнэж хэлбэл, Radford et al. (2018) судалгаа нь **decoder-only Transformer** архитектур NLP-д үр ашигтай болохыг баталж, улмаар GPT-2, GPT-3 зэрэг дараагийн **GPT цуврал загваруудын эхлэл** болсон суурь судалгаа гэж үзэгддэг.


  

---

  


## 5.10 Peters et al. (2018) – *ELMo*

Peters et al. (2018)-ийн санал болгосон **ELMo (Embeddings from Language Models)** загвар нь үгийг өгүүлбэрийн **контекстээс хамааран динамикаар өөр embedding**-ээр илэрхийлдэг **contextual representation** хандлагыг анх нэвтрүүлсэн чухал судалгаа юм. Энэ нь өмнөх static embedding аргуудаас ялгаатайгаар нэг үгийг өөр өөр нөхцөлд өөр утгатайгаар илэрхийлэх боломжийг олгосон.

### Ашигласан арга

ELMo нь **character-aware** оролттой **гүн BiLSTM хэлний загвар** дээр суурилсан. Архитектурын хувьд **2 давхаргатай BiLSTM**, **512 hidden size** ашиглаж, текстийн дарааллыг зүүн болон баруун чиглэлээс зэрэг загварчилсан.

Загварыг том хэмжээний корпус дээр хэлний загварын зорилгоор урьдчилан сургаж, дараа нь sentiment analysis зэрэг доод түвшний даалгавруудад **feature extraction** байдлаар ашигласан. Судалгаанд **IMDB Movie Reviews dataset** дээр ELMo embedding-ийг ашиглан sentiment ангилал гүйцэтгэсэн.

### Үр дүн ба дүгнэлт

Туршилтын үр дүнгээс харахад ELMo embedding ашигласан загварууд нь sentiment analysis дээр **ойролцоогоор 93% accuracy** хүрч, тухайн үеийн уламжлалт болон CNN/RNN-д суурилсан олон аргуудтай өрсөлдөхүйц гүйцэтгэл үзүүлсэн. Контекстэд суурилсан embedding ашигласнаар үгсийн олон утга, өгүүлбэрийн бүтцийг илүү нарийвчлалтай илэрхийлж чадсан нь гүйцэтгэлд шууд нөлөөлсөн.

Дүгнэж хэлбэл, Peters et al. (2018) судалгаа нь **contextual word embedding** ойлголтыг NLP-д амжилттай нэвтрүүлж, улмаар BERT, GPT зэрэг Transformer-д суурилсан contextual загваруудын хөгжлийн онолын болон практик суурь болсон чухал ажил юм.


  

---

  


## 5.11 Судалгааны ажлуудын нэгтгэсэн дүгнэлт

Дээрх судалгааны ажлуудыг нэгтгэн дүгнэхэд sentiment analysis-ийн хөгжил нь текстийн төлөөлөл (representation) болон загварчлалын аргачлалын хувьд **алхамчилсан байдлаар урагшилсан** нь тодорхой харагдаж байна.

Эхний шатанд **TF-IDF** болон **Bag-of-Words** зэрэг уламжлалт аргачлалууд ашиглагдаж, текстийг үгсийн давтамжид суурилан илэрхийлж байсан нь sentiment analysis-ийн **суурь ойлголтыг** бүрдүүлсэн. Үүний дараа **Word2Vec**, **GloVe** зэрэг word embedding аргууд нэвтэрснээр үгсийн **семантик хамаарал** болон утгын ойролцоо байдлыг вектор орон зайд илэрхийлэх боломж бүрдсэн.

Цаашлаад **CNN** болон **LSTM** зэрэг гүн сургалтын архитектурууд ашиглагдсанаар өгүүлбэрийн **бүтэц**, **дарааллын мэдээлэл**, орон нутгийн болон урт хугацааны хамаарлыг автоматаар сурч авах боломжтой болсон. Харин хамгийн сүүлийн шатанд **ELMo**, **ULMFiT**, **BERT** зэрэг **contextual deep learning** загварууд нэвтэрч, үг бүрийн утгыг тухайн өгүүлбэрийн контекстээс хамааруулан илэрхийлэх шинэ стандарт тогтсон.

Эдгээр судалгааны үр дүнгээс харахад **BERT зэрэг contextual загварууд** нь IMDB Movie Reviews dataset дээр **state-of-the-art гүйцэтгэл** үзүүлж, sentiment analysis төдийгүй NLP-ийн бусад олон даалгаварт хамгийн өргөн хэрэглэгддэг үндсэн хандлага болсон нь батлагдсан.


  

---

  


# 6. Судалгаанд ашигласан арга зүй (Methodology)

Энэхүү судалгаанд sentiment analysis хийх зорилгоор **уламжлалт машин сургалтын арга** болон **орчин үеийн гүн сургалтын загвар**-ыг харьцуулан ашигласан. Үүнд **TF-IDF + Logistic Regression**-ийг суурь (baseline) загвар болгон, **BERT**-ийг өндөр гүйцэтгэлтэй загвар болгон сонгож туршсан.

---

## 6.1 Ашигласан үндсэн аргууд

- **TF-IDF + Logistic Regression**
- **BERT (fine-tuning)**

---

## 6.2 TF-IDF + Logistic Regression

TF-IDF (Term Frequency–Inverse Document Frequency) нь үг тухайн баримт бичигт хэр чухал болохыг статистик аргаар тооцдог текстийн төлөөллийн арга юм. Энэхүү төлөөллийг ашиглан **Logistic Regression** ангилагч загвараар эерэг болон сөрөг сэтгэгдлийг ангилсан.

Logistic Regression загварын магадлал дараах байдлаар тодорхойлогдоно:

\[
P(y=1 \mid x) = \frac{1}{1 + e^{-w^T x}}
\]

Энэхүү арга нь:
- Сургалтын хурд хурдан
- Тооцооллын зардал бага
- Үр дүн ойлгомжтой

давуу талтай тул судалгаанд **baseline загвар** болгон ашигласан.

---

## 6.3 BERT арга

BERT (Bidirectional Encoder Representations from Transformers) нь **Transformer** архитектурт суурилсан бөгөөд үг бүрийн утгыг өгүүлбэрийн **хоёр чиглэлтэй контекстээс** хамааруулан илэрхийлдэг.

BERT-ийн үндсэн бүрэлдэхүүн хэсэг болох **self-attention** механизм дараах томьёогоор илэрхийлэгдэнэ:

\[
Attention(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V
\]

Энэхүү судалгаанд BERT загварыг **IMDB Movie Reviews dataset** дээр fine-tuning хийж, баримт бичгийн түвшний sentiment analysis гүйцэтгэсэн. Fine-tuning аргачлал нь загварыг тухайн даалгаварт илүү сайн дасан зохицох боломжийг олгож, өндөр гүйцэтгэл үзүүлэхэд нөлөөлсөн.

---

## 6.4 Processing Pipeline

Судалгаанд ашигласан өгөгдөл боловсруулах болон сургалтын pipeline нь дараах дараалалтай байна:

1. **Text cleaning** (тэмдэгтүүд цэвэрлэх, жижиг үсэгт шилжүүлэх)
2. **Embedding үүсгэх** (TF-IDF, BERT)
3. **Загвар сургах** (training)
4. **Test өгөгдөл дээр үнэлэх** (evaluation)

---

## 6.5 Арга сонголтын үндэслэл

Судалгаанд хоёр өөр төрлийн аргыг сонгосон нь дараах үндэслэлтэй:

- **TF-IDF + Logistic Regression**  
  → Хурдан, ойлгомжтой, суурь түвшний гүйцэтгэлийг тодорхойлох боломжтой

- **BERT**  
  → Контекст ойлголттой, орчин үеийн state-of-the-art загвар, өндөр нарийвчлал үзүүлдэг

Эдгээрийг харьцуулснаар уламжлалт болон гүн сургалтын аргуудын гүйцэтгэлийн ялгааг тодорхой харуулах боломж бүрдсэн.

---

## 6.6 Ашигласан embedding аргууд

| Embedding арга | Гол параметрүүд |
|---------------|----------------|
| TF-IDF | max_features = 10,000<br>ngram_range = (1, 2) |
| Word2Vec | vector_size = 300<br>window = 5 |
| BERT | hidden_size = 768<br>max_seq_len = 128 |

  

---

  

# 7. Үр дүнгийн үнэлгээ (Evaluation)

  

## 7.1 Үнэлгээний хэмжүүрүүд

  

- Accuracy

- Precision

- Recall

- F1-score

  

## 7.2 Туршилтын үр дүн

  

| Арга | Accuracy | Precision | Recall | F1-score |

|-----|---------|-----------|--------|----------|

| TF-IDF + LR | 0.88 | 0.87 | 0.89 | 0.88 |

| BERT | **0.94** | **0.94** | **0.95** | **0.94** |

  

---

  

# 8. Ерөнхий дүгнэлт (Conclusion)

  

Судалгааны үр дүнгээс харахад **BERT** загвар нь TF-IDF суурьтай аргыг бүх үзүүлэлтээр давсан. Иймээс бодит хэрэглээнд contextual deep learning загварууд илүү тохиромжтой.

  

---

  

# Ашигласан материал

  

(1–13 эх сурвалжуудыг хэвээр хадгална)

  
  

# F.CSC336-Natural-Language-Processing