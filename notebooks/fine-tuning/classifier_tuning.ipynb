{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecf4bf97",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a49ed51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25f9815",
   "metadata": {},
   "source": [
    "## 2. Load Word2Vec Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4577c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Word2Vec embeddings...\n",
      "\n",
      "Embeddings shape: (50000, 100)\n",
      "Labels shape: (50000,)\n",
      "\n",
      "Label distribution:\n",
      "0    25000\n",
      "1    25000\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Positive: 25000 (50.00%)\n",
      "Negative: 25000 (50.00%)\n"
     ]
    }
   ],
   "source": [
    "# Load embeddings and labels\n",
    "embeddings_path = '../../models/word2vec/document_embeddings.npy'\n",
    "labels_path = '../../models/word2vec/labels.npy'\n",
    "\n",
    "print(\"Loading Word2Vec embeddings...\")\n",
    "X = np.load(embeddings_path)\n",
    "y = np.load(labels_path)\n",
    "\n",
    "print(f\"\\nEmbeddings shape: {X.shape}\")\n",
    "print(f\"Labels shape: {y.shape}\")\n",
    "print(f\"\\nLabel distribution:\")\n",
    "print(pd.Series(y).value_counts())\n",
    "print(f\"\\nPositive: {(y==1).sum()} ({(y==1).sum()/len(y)*100:.2f}%)\")\n",
    "print(f\"Negative: {(y==0).sum()} ({(y==0).sum()/len(y)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8def5ff",
   "metadata": {},
   "source": [
    "## 3. Define Hyperparameter Grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98fd6c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameter grids defined:\n",
      "\n",
      "Logistic Regression: 11 parameters\n",
      "Random Forest: 12 parameters\n",
      "AdaBoost: 11 parameters\n",
      "MLP: 11 parameters\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression - 20 combinations\n",
    "lr_param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['liblinear', 'saga'],\n",
    "    'max_iter': [500, 1000]\n",
    "}\n",
    "\n",
    "# Random Forest - 20 combinations\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [50, 100, 200, 300],\n",
    "    'max_depth': [10, 20, 30, None],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "# AdaBoost - 20 combinations\n",
    "ada_param_grid = {\n",
    "    'n_estimators': [50, 100, 200, 300, 400],\n",
    "    'learning_rate': [0.01, 0.1, 0.5, 1.0],\n",
    "    'algorithm': ['SAMME', 'SAMME.R']\n",
    "}\n",
    "\n",
    "# MLP (Neural Network as LSTM alternative) - 20 combinations\n",
    "mlp_param_grid = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50), (100, 100)],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'alpha': [0.0001, 0.001],\n",
    "    'learning_rate': ['constant', 'adaptive']\n",
    "}\n",
    "\n",
    "print(\"Hyperparameter grids defined:\")\n",
    "print(f\"\\nLogistic Regression: {sum([len(v) for v in lr_param_grid.values()])} parameters\")\n",
    "print(f\"Random Forest: {sum([len(v) for v in rf_param_grid.values()])} parameters\")\n",
    "print(f\"AdaBoost: {sum([len(v) for v in ada_param_grid.values()])} parameters\")\n",
    "print(f\"MLP: {sum([len(v) for v in mlp_param_grid.values()])} parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5caa41b3",
   "metadata": {},
   "source": [
    "## 4. Logistic Regression - GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3e82a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "1. LOGISTIC REGRESSION - Grid Search with 5-Fold CV\n",
      "================================================================================\n",
      "\n",
      "Fitting Logistic Regression...\n",
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "[CV] END C=0.001, max_iter=500, penalty=l1, solver=liblinear; total time=   0.6s\n",
      "[CV] END C=0.001, max_iter=500, penalty=l1, solver=liblinear; total time=   0.8s\n",
      "[CV] END C=0.001, max_iter=500, penalty=l2, solver=liblinear; total time=   0.7s\n",
      "[CV] END C=0.001, max_iter=500, penalty=l1, solver=liblinear; total time=   0.6s\n",
      "[CV] END C=0.001, max_iter=500, penalty=l1, solver=liblinear; total time=   0.8s\n",
      "[CV] END C=0.001, max_iter=500, penalty=l2, solver=liblinear; total time=   0.7s\n",
      "[CV] END C=0.001, max_iter=500, penalty=l2, solver=liblinear; total time=   0.9s\n",
      "[CV] END C=0.001, max_iter=500, penalty=l2, solver=liblinear; total time=   0.9s\n",
      "[CV] END C=0.001, max_iter=500, penalty=l2, solver=liblinear; total time=   0.8s\n",
      "[CV] END .....C=0.001, max_iter=500, penalty=l2, solver=saga; total time=   1.4s\n",
      "[CV] END C=0.001, max_iter=1000, penalty=l1, solver=liblinear; total time=   0.6s\n",
      "[CV] END C=0.001, max_iter=500, penalty=l2, solver=liblinear; total time=   1.0s\n",
      "[CV] END C=0.001, max_iter=500, penalty=l2, solver=liblinear; total time=   0.8s\n",
      "[CV] END .....C=0.001, max_iter=500, penalty=l2, solver=saga; total time=   1.4s\n",
      "[CV] END C=0.001, max_iter=1000, penalty=l1, solver=liblinear; total time=   0.6s\n",
      "[CV] END C=0.001, max_iter=500, penalty=l2, solver=liblinear; total time=   1.0s\n",
      "[CV] END .....C=0.001, max_iter=500, penalty=l1, solver=saga; total time=   1.5s\n",
      "[CV] END C=0.001, max_iter=1000, penalty=l1, solver=liblinear; total time=   0.8s\n",
      "[CV] END .....C=0.001, max_iter=500, penalty=l2, solver=saga; total time=   1.5s\n",
      "[CV] END C=0.001, max_iter=500, penalty=l1, solver=liblinear; total time=   1.0s\n",
      "[CV] END .....C=0.001, max_iter=500, penalty=l1, solver=saga; total time=   1.5s\n",
      "[CV] END C=0.001, max_iter=1000, penalty=l1, solver=liblinear; total time=   0.8s\n",
      "[CV] END .....C=0.001, max_iter=500, penalty=l2, solver=saga; total time=   1.5s\n",
      "[CV] END C=0.001, max_iter=500, penalty=l1, solver=liblinear; total time=   1.0s\n",
      "[CV] END C=0.001, max_iter=500, penalty=l1, solver=liblinear; total time=   0.7s\n",
      "[CV] END C=0.001, max_iter=500, penalty=l1, solver=liblinear; total time=   1.1s\n",
      "[CV] END .....C=0.001, max_iter=500, penalty=l1, solver=saga; total time=   1.2s\n",
      "[CV] END .....C=0.001, max_iter=500, penalty=l1, solver=saga; total time=   1.9s\n",
      "[CV] END .....C=0.001, max_iter=500, penalty=l1, solver=saga; total time=   1.8s\n",
      "[CV] END C=0.001, max_iter=1000, penalty=l1, solver=liblinear; total time=   0.9s\n",
      "[CV] END .....C=0.001, max_iter=500, penalty=l2, solver=saga; total time=   1.5s\n",
      "[CV] END C=0.001, max_iter=1000, penalty=l1, solver=liblinear; total time=   0.6s\n",
      "[CV] END C=0.001, max_iter=500, penalty=l1, solver=liblinear; total time=   0.7s\n",
      "[CV] END C=0.001, max_iter=500, penalty=l1, solver=liblinear; total time=   1.1s\n",
      "[CV] END .....C=0.001, max_iter=500, penalty=l1, solver=saga; total time=   1.2s\n",
      "[CV] END .....C=0.001, max_iter=500, penalty=l1, solver=saga; total time=   1.9s\n",
      "[CV] END .....C=0.001, max_iter=500, penalty=l1, solver=saga; total time=   1.8s\n",
      "[CV] END C=0.001, max_iter=1000, penalty=l1, solver=liblinear; total time=   0.9s\n",
      "[CV] END .....C=0.001, max_iter=500, penalty=l2, solver=saga; total time=   1.5s\n",
      "[CV] END C=0.001, max_iter=1000, penalty=l1, solver=liblinear; total time=   0.6s\n",
      "[CV] END C=0.001, max_iter=1000, penalty=l1, solver=liblinear; total time=   1.1s\n",
      "[CV] END C=0.001, max_iter=1000, penalty=l1, solver=liblinear; total time=   1.1s\n",
      "[CV] END C=0.001, max_iter=500, penalty=l2, solver=liblinear; total time=   1.3s\n",
      "[CV] END .....C=0.001, max_iter=500, penalty=l1, solver=saga; total time=   2.0s\n",
      "[CV] END .....C=0.001, max_iter=500, penalty=l2, solver=saga; total time=   1.8s\n",
      "[CV] END C=0.001, max_iter=1000, penalty=l2, solver=liblinear; total time=   0.6s\n",
      "[CV] END C=0.001, max_iter=500, penalty=l2, solver=liblinear; total time=   1.3s\n",
      "[CV] END .....C=0.001, max_iter=500, penalty=l1, solver=saga; total time=   2.0s\n",
      "[CV] END .....C=0.001, max_iter=500, penalty=l2, solver=saga; total time=   1.8s\n",
      "[CV] END C=0.001, max_iter=1000, penalty=l2, solver=liblinear; total time=   0.6s\n",
      "[CV] END ....C=0.001, max_iter=1000, penalty=l1, solver=saga; total time=   1.0s\n",
      "[CV] END C=0.001, max_iter=1000, penalty=l2, solver=liblinear; total time=   0.8s\n",
      "[CV] END C=0.001, max_iter=1000, penalty=l2, solver=liblinear; total time=   0.8s\n",
      "[CV] END ....C=0.001, max_iter=1000, penalty=l1, solver=saga; total time=   1.0s\n",
      "[CV] END C=0.001, max_iter=1000, penalty=l2, solver=liblinear; total time=   0.8s\n",
      "[CV] END C=0.001, max_iter=1000, penalty=l2, solver=liblinear; total time=   0.8s\n",
      "[CV] END .....C=0.001, max_iter=500, penalty=l2, solver=saga; total time=   2.4s\n",
      "[CV] END ....C=0.001, max_iter=1000, penalty=l1, solver=saga; total time=   1.6s\n",
      "[CV] END C=0.001, max_iter=1000, penalty=l2, solver=liblinear; total time=   1.3s\n",
      "[CV] END C=0.001, max_iter=1000, penalty=l2, solver=liblinear; total time=   1.2s\n",
      "[CV] END .....C=0.001, max_iter=500, penalty=l2, solver=saga; total time=   2.4s\n",
      "[CV] END ....C=0.001, max_iter=1000, penalty=l1, solver=saga; total time=   1.6s\n",
      "[CV] END C=0.001, max_iter=1000, penalty=l2, solver=liblinear; total time=   1.3s\n",
      "[CV] END C=0.001, max_iter=1000, penalty=l2, solver=liblinear; total time=   1.2s\n",
      "[CV] END ....C=0.001, max_iter=1000, penalty=l2, solver=saga; total time=   1.3s\n",
      "[CV] END ....C=0.001, max_iter=1000, penalty=l2, solver=saga; total time=   1.3s\n",
      "[CV] END ....C=0.001, max_iter=1000, penalty=l1, solver=saga; total time=   1.8s\n",
      "[CV] END ....C=0.001, max_iter=1000, penalty=l1, solver=saga; total time=   1.8s\n",
      "[CV] END ....C=0.001, max_iter=1000, penalty=l2, solver=saga; total time=   1.3s\n",
      "[CV] END ....C=0.001, max_iter=1000, penalty=l2, solver=saga; total time=   1.3s\n",
      "[CV] END ....C=0.001, max_iter=1000, penalty=l1, solver=saga; total time=   1.8s\n",
      "[CV] END ....C=0.001, max_iter=1000, penalty=l1, solver=saga; total time=   1.8s\n",
      "[CV] END ....C=0.001, max_iter=1000, penalty=l1, solver=saga; total time=   2.0s\n",
      "[CV] END ....C=0.001, max_iter=1000, penalty=l1, solver=saga; total time=   2.0s\n",
      "[CV] END ....C=0.001, max_iter=1000, penalty=l2, solver=saga; total time=   2.0s\n",
      "[CV] END ....C=0.001, max_iter=1000, penalty=l2, solver=saga; total time=   2.2s\n",
      "[CV] END ....C=0.001, max_iter=1000, penalty=l2, solver=saga; total time=   2.2s\n",
      "[CV] END ....C=0.001, max_iter=1000, penalty=l2, solver=saga; total time=   2.0s\n",
      "[CV] END ....C=0.001, max_iter=1000, penalty=l2, solver=saga; total time=   2.2s\n",
      "[CV] END ....C=0.001, max_iter=1000, penalty=l2, solver=saga; total time=   2.2s\n",
      "[CV] END .C=0.01, max_iter=500, penalty=l2, solver=liblinear; total time=   1.6s\n",
      "[CV] END .C=0.01, max_iter=500, penalty=l2, solver=liblinear; total time=   1.5s\n",
      "[CV] END .C=0.01, max_iter=500, penalty=l2, solver=liblinear; total time=   1.6s\n",
      "[CV] END .C=0.01, max_iter=500, penalty=l2, solver=liblinear; total time=   1.6s\n",
      "[CV] END .C=0.01, max_iter=500, penalty=l2, solver=liblinear; total time=   1.5s\n",
      "[CV] END .C=0.01, max_iter=500, penalty=l2, solver=liblinear; total time=   1.6s\n",
      "[CV] END .C=0.01, max_iter=500, penalty=l2, solver=liblinear; total time=   1.6s\n",
      "[CV] END .C=0.01, max_iter=500, penalty=l2, solver=liblinear; total time=   1.6s\n",
      "[CV] END ......C=0.01, max_iter=500, penalty=l1, solver=saga; total time=   2.8s\n",
      "[CV] END .C=0.01, max_iter=500, penalty=l2, solver=liblinear; total time=   2.5s\n",
      "[CV] END ......C=0.01, max_iter=500, penalty=l1, solver=saga; total time=   2.8s\n",
      "[CV] END .C=0.01, max_iter=500, penalty=l2, solver=liblinear; total time=   2.5s\n",
      "[CV] END ......C=0.01, max_iter=500, penalty=l2, solver=saga; total time=   2.4s\n",
      "[CV] END ......C=0.01, max_iter=500, penalty=l2, solver=saga; total time=   2.4s\n",
      "[CV] END ......C=0.01, max_iter=500, penalty=l2, solver=saga; total time=   3.0s\n",
      "[CV] END ......C=0.01, max_iter=500, penalty=l2, solver=saga; total time=   3.0s\n",
      "[CV] END .C=0.01, max_iter=500, penalty=l1, solver=liblinear; total time=   5.4s\n",
      "[CV] END ......C=0.01, max_iter=500, penalty=l2, solver=saga; total time=   3.4s\n",
      "[CV] END ......C=0.01, max_iter=500, penalty=l2, solver=saga; total time=   3.4s\n",
      "[CV] END .C=0.01, max_iter=500, penalty=l1, solver=liblinear; total time=   5.4s\n",
      "[CV] END ......C=0.01, max_iter=500, penalty=l2, solver=saga; total time=   3.4s\n",
      "[CV] END ......C=0.01, max_iter=500, penalty=l2, solver=saga; total time=   3.4s\n",
      "[CV] END ......C=0.01, max_iter=500, penalty=l2, solver=saga; total time=   3.6s\n",
      "[CV] END .C=0.01, max_iter=500, penalty=l1, solver=liblinear; total time=   5.4s[CV] END ......C=0.01, max_iter=500, penalty=l2, solver=saga; total time=   3.6s\n",
      "[CV] END .C=0.01, max_iter=500, penalty=l1, solver=liblinear; total time=   5.4s\n",
      "\n",
      "[CV] END .....C=0.01, max_iter=1000, penalty=l1, solver=saga; total time=   2.5s\n",
      "[CV] END .....C=0.01, max_iter=1000, penalty=l1, solver=saga; total time=   2.5s\n",
      "[CV] END C=0.01, max_iter=1000, penalty=l2, solver=liblinear; total time=   1.3s\n",
      "[CV] END C=0.01, max_iter=1000, penalty=l2, solver=liblinear; total time=   1.3s\n",
      "[CV] END .C=0.01, max_iter=500, penalty=l1, solver=liblinear; total time=   6.7s\n",
      "[CV] END .C=0.01, max_iter=500, penalty=l1, solver=liblinear; total time=   6.8s\n",
      "[CV] END C=0.01, max_iter=1000, penalty=l2, solver=liblinear; total time=   1.4s\n",
      "[CV] END .C=0.01, max_iter=500, penalty=l1, solver=liblinear; total time=   6.7s\n",
      "[CV] END .C=0.01, max_iter=500, penalty=l1, solver=liblinear; total time=   6.8s\n",
      "[CV] END C=0.01, max_iter=1000, penalty=l2, solver=liblinear; total time=   1.4s\n",
      "[CV] END C=0.01, max_iter=1000, penalty=l2, solver=liblinear; total time=   1.7s\n",
      "[CV] END C=0.01, max_iter=1000, penalty=l2, solver=liblinear; total time=   1.7s\n",
      "[CV] END .C=0.01, max_iter=500, penalty=l1, solver=liblinear; total time=   7.5s\n",
      "[CV] END C=0.01, max_iter=1000, penalty=l2, solver=liblinear; total time=   1.3s\n",
      "[CV] END .C=0.01, max_iter=500, penalty=l1, solver=liblinear; total time=   7.5s\n",
      "[CV] END C=0.01, max_iter=1000, penalty=l2, solver=liblinear; total time=   1.3s\n",
      "[CV] END C=0.01, max_iter=1000, penalty=l2, solver=liblinear; total time=   2.2s\n",
      "[CV] END C=0.01, max_iter=1000, penalty=l1, solver=liblinear; total time=   5.6s\n",
      "[CV] END C=0.01, max_iter=1000, penalty=l1, solver=liblinear; total time=   5.9s\n",
      "[CV] END C=0.01, max_iter=1000, penalty=l2, solver=liblinear; total time=   2.2s\n",
      "[CV] END C=0.01, max_iter=1000, penalty=l1, solver=liblinear; total time=   5.6s\n",
      "[CV] END C=0.01, max_iter=1000, penalty=l1, solver=liblinear; total time=   5.9s\n",
      "[CV] END .....C=0.01, max_iter=1000, penalty=l2, solver=saga; total time=   2.3s\n",
      "[CV] END .....C=0.01, max_iter=1000, penalty=l2, solver=saga; total time=   2.5s\n",
      "[CV] END .....C=0.01, max_iter=1000, penalty=l2, solver=saga; total time=   2.5s\n",
      "[CV] END .....C=0.01, max_iter=1000, penalty=l2, solver=saga; total time=   2.3s\n",
      "[CV] END .....C=0.01, max_iter=1000, penalty=l2, solver=saga; total time=   2.5s\n",
      "[CV] END .....C=0.01, max_iter=1000, penalty=l2, solver=saga; total time=   2.5s\n",
      "[CV] END C=0.01, max_iter=1000, penalty=l1, solver=liblinear; total time=   7.2s\n",
      "[CV] END .....C=0.01, max_iter=1000, penalty=l2, solver=saga; total time=   2.6s\n",
      "[CV] END C=0.01, max_iter=1000, penalty=l1, solver=liblinear; total time=   7.2s\n",
      "[CV] END .....C=0.01, max_iter=1000, penalty=l2, solver=saga; total time=   2.6s\n",
      "[CV] END C=0.01, max_iter=1000, penalty=l1, solver=liblinear; total time=   7.2s\n",
      "[CV] END C=0.01, max_iter=1000, penalty=l1, solver=liblinear; total time=   7.2s\n",
      "[CV] END C=0.01, max_iter=1000, penalty=l1, solver=liblinear; total time=   8.1s\n",
      "[CV] END C=0.01, max_iter=1000, penalty=l1, solver=liblinear; total time=   8.1s\n",
      "[CV] END .....C=0.01, max_iter=1000, penalty=l2, solver=saga; total time=   4.1s\n",
      "[CV] END .....C=0.01, max_iter=1000, penalty=l2, solver=saga; total time=   4.1s\n",
      "[CV] END ..C=0.1, max_iter=500, penalty=l2, solver=liblinear; total time=   3.8s\n",
      "[CV] END ..C=0.1, max_iter=500, penalty=l2, solver=liblinear; total time=   3.8s\n",
      "[CV] END ..C=0.1, max_iter=500, penalty=l2, solver=liblinear; total time=   3.1s\n",
      "[CV] END ..C=0.1, max_iter=500, penalty=l2, solver=liblinear; total time=   3.1s\n",
      "[CV] END ..C=0.1, max_iter=500, penalty=l2, solver=liblinear; total time=   3.5s\n",
      "[CV] END ..C=0.1, max_iter=500, penalty=l2, solver=liblinear; total time=   3.5s\n",
      "[CV] END ..C=0.1, max_iter=500, penalty=l2, solver=liblinear; total time=   3.1s\n",
      "[CV] END ..C=0.1, max_iter=500, penalty=l2, solver=liblinear; total time=   3.1s\n",
      "[CV] END ..C=0.1, max_iter=500, penalty=l2, solver=liblinear; total time=   2.1s\n",
      "[CV] END ..C=0.1, max_iter=500, penalty=l2, solver=liblinear; total time=   2.1s\n",
      "[CV] END .......C=0.1, max_iter=500, penalty=l1, solver=saga; total time=  13.3s\n",
      "[CV] END .......C=0.1, max_iter=500, penalty=l1, solver=saga; total time=  13.3s\n",
      "[CV] END .......C=0.1, max_iter=500, penalty=l1, solver=saga; total time=  14.4s\n",
      "[CV] END .......C=0.1, max_iter=500, penalty=l1, solver=saga; total time=  14.4s\n",
      "[CV] END .......C=0.1, max_iter=500, penalty=l1, solver=saga; total time=  14.6s\n",
      "[CV] END .......C=0.1, max_iter=500, penalty=l1, solver=saga; total time=  14.6s\n",
      "[CV] END .......C=0.1, max_iter=500, penalty=l2, solver=saga; total time=   7.2s\n",
      "[CV] END .......C=0.1, max_iter=500, penalty=l2, solver=saga; total time=   7.2s\n",
      "[CV] END .......C=0.1, max_iter=500, penalty=l1, solver=saga; total time=  16.5s\n",
      "[CV] END .......C=0.1, max_iter=500, penalty=l1, solver=saga; total time=  16.5s\n",
      "[CV] END .......C=0.1, max_iter=500, penalty=l1, solver=saga; total time=  16.5s\n",
      "[CV] END .......C=0.1, max_iter=500, penalty=l1, solver=saga; total time=  16.5s\n",
      "[CV] END .......C=0.1, max_iter=500, penalty=l2, solver=saga; total time=   8.3s\n",
      "[CV] END .......C=0.1, max_iter=500, penalty=l2, solver=saga; total time=   8.3s\n",
      "[CV] END .......C=0.1, max_iter=500, penalty=l2, solver=saga; total time=   8.1s\n",
      "[CV] END .......C=0.1, max_iter=500, penalty=l2, solver=saga; total time=   8.1s\n",
      "[CV] END .......C=0.1, max_iter=500, penalty=l2, solver=saga; total time=  11.4s\n",
      "[CV] END .......C=0.1, max_iter=500, penalty=l2, solver=saga; total time=  11.4s\n",
      "[CV] END .......C=0.1, max_iter=500, penalty=l2, solver=saga; total time=  12.5s\n",
      "[CV] END .......C=0.1, max_iter=500, penalty=l2, solver=saga; total time=  12.5s\n",
      "[CV] END ......C=0.1, max_iter=1000, penalty=l1, solver=saga; total time=  12.0s\n",
      "[CV] END ......C=0.1, max_iter=1000, penalty=l1, solver=saga; total time=  12.0s\n",
      "[CV] END ......C=0.1, max_iter=1000, penalty=l1, solver=saga; total time=  17.9s\n",
      "[CV] END ......C=0.1, max_iter=1000, penalty=l1, solver=saga; total time=  17.9s\n",
      "[CV] END ......C=0.1, max_iter=1000, penalty=l1, solver=saga; total time=  11.1s\n",
      "[CV] END ......C=0.1, max_iter=1000, penalty=l1, solver=saga; total time=  11.1s\n",
      "[CV] END ......C=0.01, max_iter=500, penalty=l1, solver=saga; total time= 1.0min\n",
      "[CV] END ......C=0.01, max_iter=500, penalty=l1, solver=saga; total time= 1.0min\n",
      "[CV] END .C=0.1, max_iter=1000, penalty=l2, solver=liblinear; total time=   2.5s\n",
      "[CV] END .C=0.1, max_iter=1000, penalty=l2, solver=liblinear; total time=   2.5s\n",
      "[CV] END ......C=0.01, max_iter=500, penalty=l1, solver=saga; total time= 1.1min\n",
      "[CV] END ......C=0.01, max_iter=500, penalty=l1, solver=saga; total time= 1.1min\n",
      "[CV] END .C=0.1, max_iter=1000, penalty=l2, solver=liblinear; total time=   2.5s\n",
      "[CV] END .C=0.1, max_iter=1000, penalty=l2, solver=liblinear; total time=   2.5s\n",
      "[CV] END .C=0.1, max_iter=1000, penalty=l2, solver=liblinear; total time=   2.0s\n",
      "[CV] END .C=0.1, max_iter=1000, penalty=l2, solver=liblinear; total time=   2.0s\n",
      "[CV] END ......C=0.1, max_iter=1000, penalty=l1, solver=saga; total time=  15.8s\n",
      "[CV] END ......C=0.1, max_iter=1000, penalty=l1, solver=saga; total time=  15.8s\n",
      "[CV] END .C=0.1, max_iter=1000, penalty=l2, solver=liblinear; total time=   1.9s\n",
      "[CV] END .C=0.1, max_iter=1000, penalty=l2, solver=liblinear; total time=   3.2s\n",
      "[CV] END .C=0.1, max_iter=1000, penalty=l2, solver=liblinear; total time=   1.9s\n",
      "[CV] END .C=0.1, max_iter=1000, penalty=l2, solver=liblinear; total time=   3.2s\n",
      "[CV] END ......C=0.01, max_iter=500, penalty=l1, solver=saga; total time= 1.2min\n",
      "[CV] END ......C=0.01, max_iter=500, penalty=l1, solver=saga; total time= 1.2min\n",
      "[CV] END ......C=0.01, max_iter=500, penalty=l1, solver=saga; total time= 1.2min\n",
      "[CV] END ......C=0.01, max_iter=500, penalty=l1, solver=saga; total time= 1.2min\n",
      "[CV] END ......C=0.1, max_iter=1000, penalty=l1, solver=saga; total time=  14.9s\n",
      "[CV] END ......C=0.1, max_iter=1000, penalty=l1, solver=saga; total time=  14.9s\n",
      "[CV] END ......C=0.1, max_iter=1000, penalty=l2, solver=saga; total time=   8.2s\n",
      "[CV] END ......C=0.1, max_iter=1000, penalty=l2, solver=saga; total time=   8.2s\n",
      "[CV] END ......C=0.1, max_iter=1000, penalty=l2, solver=saga; total time=   8.5s\n",
      "[CV] END ......C=0.1, max_iter=1000, penalty=l2, solver=saga; total time=   8.5s\n",
      "[CV] END ......C=0.1, max_iter=1000, penalty=l2, solver=saga; total time=  11.2s\n",
      "[CV] END ......C=0.1, max_iter=1000, penalty=l2, solver=saga; total time=  11.2s\n",
      "[CV] END ......C=0.1, max_iter=1000, penalty=l2, solver=saga; total time=   9.9s\n",
      "[CV] END ......C=0.1, max_iter=1000, penalty=l2, solver=saga; total time=   9.9s\n",
      "[CV] END ......C=0.1, max_iter=1000, penalty=l2, solver=saga; total time=  10.8s\n",
      "[CV] END ......C=0.1, max_iter=1000, penalty=l2, solver=saga; total time=  10.8s\n",
      "[CV] END ..C=0.1, max_iter=500, penalty=l1, solver=liblinear; total time= 1.3min\n",
      "[CV] END ..C=0.1, max_iter=500, penalty=l1, solver=liblinear; total time= 1.3min\n",
      "[CV] END ..C=0.1, max_iter=500, penalty=l1, solver=liblinear; total time= 1.5min\n",
      "[CV] END ..C=0.1, max_iter=500, penalty=l1, solver=liblinear; total time= 1.5min\n",
      "[CV] END ..C=0.1, max_iter=500, penalty=l1, solver=liblinear; total time= 1.5min\n",
      "[CV] END ..C=0.1, max_iter=500, penalty=l1, solver=liblinear; total time= 1.5min\n",
      "[CV] END .C=0.1, max_iter=1000, penalty=l1, solver=liblinear; total time= 1.3min\n",
      "[CV] END .........C=1, max_iter=500, penalty=l1, solver=saga; total time=  22.9s\n",
      "[CV] END .C=0.1, max_iter=1000, penalty=l1, solver=liblinear; total time= 1.3min\n",
      "[CV] END .........C=1, max_iter=500, penalty=l1, solver=saga; total time=  22.9s\n",
      "[CV] END ....C=1, max_iter=500, penalty=l2, solver=liblinear; total time=   2.7s\n",
      "[CV] END ....C=1, max_iter=500, penalty=l2, solver=liblinear; total time=   2.7s\n",
      "[CV] END .........C=1, max_iter=500, penalty=l1, solver=saga; total time=  29.7s\n",
      "[CV] END .........C=1, max_iter=500, penalty=l1, solver=saga; total time=  29.7s\n",
      "[CV] END ....C=1, max_iter=500, penalty=l2, solver=liblinear; total time=   3.2s\n",
      "[CV] END ....C=1, max_iter=500, penalty=l2, solver=liblinear; total time=   3.2s\n",
      "[CV] END .C=0.1, max_iter=1000, penalty=l1, solver=liblinear; total time= 1.5min\n",
      "[CV] END .C=0.1, max_iter=1000, penalty=l1, solver=liblinear; total time= 1.5min\n",
      "[CV] END ....C=1, max_iter=500, penalty=l2, solver=liblinear; total time=   3.8s\n",
      "[CV] END ..C=0.1, max_iter=500, penalty=l1, solver=liblinear; total time= 1.8min\n",
      "[CV] END ....C=1, max_iter=500, penalty=l2, solver=liblinear; total time=   3.8s\n",
      "[CV] END ..C=0.1, max_iter=500, penalty=l1, solver=liblinear; total time= 1.8min\n",
      "[CV] END ....C=1, max_iter=500, penalty=l2, solver=liblinear; total time=   4.7s\n",
      "[CV] END ....C=1, max_iter=500, penalty=l2, solver=liblinear; total time=   4.7s\n",
      "[CV] END ....C=1, max_iter=500, penalty=l2, solver=liblinear; total time=   2.9s\n",
      "[CV] END ....C=1, max_iter=500, penalty=l2, solver=liblinear; total time=   2.9s\n",
      "[CV] END ..C=0.1, max_iter=500, penalty=l1, solver=liblinear; total time= 1.9min\n",
      "[CV] END ..C=0.1, max_iter=500, penalty=l1, solver=liblinear; total time= 1.9min\n",
      "[CV] END .........C=1, max_iter=500, penalty=l1, solver=saga; total time=  24.5s\n",
      "[CV] END .........C=1, max_iter=500, penalty=l1, solver=saga; total time=  24.5s\n",
      "[CV] END .C=0.1, max_iter=1000, penalty=l1, solver=liblinear; total time= 1.7min\n",
      "[CV] END .C=0.1, max_iter=1000, penalty=l1, solver=liblinear; total time= 1.7min\n",
      "[CV] END .........C=1, max_iter=500, penalty=l1, solver=saga; total time=  27.6s\n",
      "[CV] END .........C=1, max_iter=500, penalty=l1, solver=saga; total time=  21.6s\n",
      "[CV] END .........C=1, max_iter=500, penalty=l1, solver=saga; total time=  27.6s\n",
      "[CV] END .........C=1, max_iter=500, penalty=l1, solver=saga; total time=  21.6s\n",
      "[CV] END .C=0.1, max_iter=1000, penalty=l1, solver=liblinear; total time= 1.7min\n",
      "[CV] END .C=0.1, max_iter=1000, penalty=l1, solver=liblinear; total time= 1.7min\n",
      "[CV] END .C=0.1, max_iter=1000, penalty=l1, solver=liblinear; total time= 1.9min\n",
      "[CV] END .....C=0.01, max_iter=1000, penalty=l1, solver=saga; total time= 2.3min\n",
      "[CV] END .C=0.1, max_iter=1000, penalty=l1, solver=liblinear; total time= 1.9min\n",
      "[CV] END .....C=0.01, max_iter=1000, penalty=l1, solver=saga; total time= 2.3min\n",
      "[CV] END .....C=0.01, max_iter=1000, penalty=l1, solver=saga; total time= 2.3min\n",
      "[CV] END .....C=0.01, max_iter=1000, penalty=l1, solver=saga; total time= 2.3min\n",
      "[CV] END .....C=0.01, max_iter=1000, penalty=l1, solver=saga; total time= 2.4min\n",
      "[CV] END .....C=0.01, max_iter=1000, penalty=l1, solver=saga; total time= 2.4min\n",
      "[CV] END .....C=0.01, max_iter=1000, penalty=l1, solver=saga; total time= 2.5min\n",
      "[CV] END .....C=0.01, max_iter=1000, penalty=l1, solver=saga; total time= 2.5min\n",
      "[CV] END ........C=1, max_iter=1000, penalty=l1, solver=saga; total time=  18.8s\n",
      "[CV] END ........C=1, max_iter=1000, penalty=l1, solver=saga; total time=  18.8s\n",
      "[CV] END ...C=1, max_iter=1000, penalty=l2, solver=liblinear; total time=   2.1s\n",
      "[CV] END ...C=1, max_iter=1000, penalty=l2, solver=liblinear; total time=   2.1s\n",
      "[CV] END ........C=1, max_iter=1000, penalty=l1, solver=saga; total time=  21.5s\n",
      "[CV] END ........C=1, max_iter=1000, penalty=l1, solver=saga; total time=  21.5s\n",
      "[CV] END ........C=1, max_iter=1000, penalty=l1, solver=saga; total time=  17.1s\n",
      "[CV] END ........C=1, max_iter=1000, penalty=l1, solver=saga; total time=  17.1s\n",
      "[CV] END ........C=1, max_iter=1000, penalty=l1, solver=saga; total time=  20.0s\n",
      "[CV] END ........C=1, max_iter=1000, penalty=l1, solver=saga; total time=  20.0s\n",
      "[CV] END ...C=1, max_iter=1000, penalty=l2, solver=liblinear; total time=   2.8s\n",
      "[CV] END ...C=1, max_iter=1000, penalty=l2, solver=liblinear; total time=   2.8s\n",
      "[CV] END .........C=1, max_iter=500, penalty=l2, solver=saga; total time=  48.2s\n",
      "[CV] END ...C=1, max_iter=1000, penalty=l2, solver=liblinear; total time=   3.0s\n",
      "[CV] END .........C=1, max_iter=500, penalty=l2, solver=saga; total time=  48.2s\n",
      "[CV] END ...C=1, max_iter=1000, penalty=l2, solver=liblinear; total time=   3.0s\n",
      "[CV] END ...C=1, max_iter=1000, penalty=l2, solver=liblinear; total time=   2.6s\n",
      "[CV] END ...C=1, max_iter=1000, penalty=l2, solver=liblinear; total time=   2.6s\n",
      "[CV] END ...C=1, max_iter=1000, penalty=l2, solver=liblinear; total time=   2.8s\n",
      "[CV] END ...C=1, max_iter=1000, penalty=l2, solver=liblinear; total time=   2.8s\n",
      "[CV] END .........C=1, max_iter=500, penalty=l2, solver=saga; total time=  52.8s\n",
      "[CV] END .........C=1, max_iter=500, penalty=l2, solver=saga; total time=  52.8s\n",
      "[CV] END .........C=1, max_iter=500, penalty=l2, solver=saga; total time=  55.6s\n",
      "[CV] END .........C=1, max_iter=500, penalty=l2, solver=saga; total time=  55.6s\n",
      "[CV] END .........C=1, max_iter=500, penalty=l2, solver=saga; total time= 1.0min\n",
      "[CV] END .........C=1, max_iter=500, penalty=l2, solver=saga; total time= 1.0min\n",
      "[CV] END .........C=1, max_iter=500, penalty=l2, solver=saga; total time=  57.6s\n",
      "[CV] END .........C=1, max_iter=500, penalty=l2, solver=saga; total time=  57.6s\n",
      "[CV] END ........C=1, max_iter=1000, penalty=l1, solver=saga; total time=  35.2s\n",
      "[CV] END ........C=1, max_iter=1000, penalty=l1, solver=saga; total time=  35.2s\n",
      "[CV] END ........C=1, max_iter=1000, penalty=l2, solver=saga; total time= 1.9min\n",
      "[CV] END ........C=1, max_iter=1000, penalty=l2, solver=saga; total time= 1.9min\n",
      "[CV] END ........C=1, max_iter=1000, penalty=l2, solver=saga; total time= 2.0min\n",
      "[CV] END ........C=1, max_iter=1000, penalty=l2, solver=saga; total time= 2.0min\n",
      "[CV] END ........C=1, max_iter=1000, penalty=l2, solver=saga; total time= 2.0min\n",
      "[CV] END ........C=1, max_iter=1000, penalty=l2, solver=saga; total time= 2.0min\n",
      "[CV] END ........C=1, max_iter=1000, penalty=l2, solver=saga; total time= 2.0min\n",
      "[CV] END ........C=1, max_iter=1000, penalty=l2, solver=saga; total time= 2.0min\n",
      "[CV] END ........C=1, max_iter=1000, penalty=l2, solver=saga; total time= 2.1min\n",
      "[CV] END ........C=1, max_iter=1000, penalty=l2, solver=saga; total time= 2.1min\n",
      "[CV] END ....C=1, max_iter=500, penalty=l1, solver=liblinear; total time= 3.6min\n",
      "[CV] END ....C=1, max_iter=500, penalty=l1, solver=liblinear; total time= 3.6min\n",
      "[CV] END ....C=1, max_iter=500, penalty=l1, solver=liblinear; total time= 3.7min\n",
      "[CV] END ....C=1, max_iter=500, penalty=l1, solver=liblinear; total time= 3.7min\n",
      "[CV] END ....C=1, max_iter=500, penalty=l1, solver=liblinear; total time= 3.7min\n",
      "[CV] END ....C=1, max_iter=500, penalty=l1, solver=liblinear; total time= 3.7min\n",
      "[CV] END ...C=10, max_iter=500, penalty=l2, solver=liblinear; total time=   4.4s\n",
      "[CV] END ...C=10, max_iter=500, penalty=l2, solver=liblinear; total time=   4.4s\n",
      "[CV] END ...C=10, max_iter=500, penalty=l2, solver=liblinear; total time=   3.7s\n",
      "[CV] END ...C=10, max_iter=500, penalty=l2, solver=liblinear; total time=   3.7s\n",
      "[CV] END ...C=10, max_iter=500, penalty=l2, solver=liblinear; total time=   4.2s\n",
      "[CV] END ...C=10, max_iter=500, penalty=l2, solver=liblinear; total time=   4.2s\n",
      "[CV] END ...C=10, max_iter=500, penalty=l2, solver=liblinear; total time=   4.9s\n",
      "[CV] END ...C=10, max_iter=500, penalty=l2, solver=liblinear; total time=   4.9s\n",
      "[CV] END ...C=10, max_iter=500, penalty=l2, solver=liblinear; total time=   3.9s\n",
      "[CV] END ...C=10, max_iter=500, penalty=l2, solver=liblinear; total time=   3.9s\n",
      "[CV] END ........C=10, max_iter=500, penalty=l1, solver=saga; total time=  28.5s\n",
      "[CV] END ........C=10, max_iter=500, penalty=l1, solver=saga; total time=  28.5s\n",
      "[CV] END ........C=10, max_iter=500, penalty=l1, solver=saga; total time=  25.5s\n",
      "[CV] END ........C=10, max_iter=500, penalty=l1, solver=saga; total time=  25.5s\n",
      "[CV] END ........C=10, max_iter=500, penalty=l1, solver=saga; total time=  31.9s\n",
      "[CV] END ........C=10, max_iter=500, penalty=l1, solver=saga; total time=  31.9s\n",
      "[CV] END ........C=10, max_iter=500, penalty=l1, solver=saga; total time=  33.8s\n",
      "[CV] END ........C=10, max_iter=500, penalty=l1, solver=saga; total time=  32.9s\n",
      "[CV] END ........C=10, max_iter=500, penalty=l1, solver=saga; total time=  33.8s\n",
      "[CV] END ........C=10, max_iter=500, penalty=l1, solver=saga; total time=  32.9s\n",
      "[CV] END ....C=1, max_iter=500, penalty=l1, solver=liblinear; total time= 4.2min\n",
      "[CV] END ....C=1, max_iter=500, penalty=l1, solver=liblinear; total time= 4.2min\n",
      "[CV] END ........C=10, max_iter=500, penalty=l2, solver=saga; total time=  29.1s\n",
      "[CV] END ........C=10, max_iter=500, penalty=l2, solver=saga; total time=  29.1s\n",
      "[CV] END ........C=10, max_iter=500, penalty=l2, solver=saga; total time=  36.5s\n",
      "[CV] END ........C=10, max_iter=500, penalty=l2, solver=saga; total time=  36.5s\n",
      "[CV] END ........C=10, max_iter=500, penalty=l2, solver=saga; total time=  34.0s\n",
      "[CV] END ........C=10, max_iter=500, penalty=l2, solver=saga; total time=  37.9s\n",
      "[CV] END ........C=10, max_iter=500, penalty=l2, solver=saga; total time=  34.0s\n",
      "[CV] END ........C=10, max_iter=500, penalty=l2, solver=saga; total time=  37.9s\n",
      "[CV] END ...C=1, max_iter=1000, penalty=l1, solver=liblinear; total time= 3.8min\n",
      "[CV] END ...C=1, max_iter=1000, penalty=l1, solver=liblinear; total time= 3.8min\n",
      "[CV] END ........C=10, max_iter=500, penalty=l2, solver=saga; total time=  41.9s\n",
      "[CV] END ........C=10, max_iter=500, penalty=l2, solver=saga; total time=  41.9s\n",
      "[CV] END ...C=1, max_iter=1000, penalty=l1, solver=liblinear; total time= 3.9min\n",
      "[CV] END ...C=1, max_iter=1000, penalty=l1, solver=liblinear; total time= 3.9min\n",
      "[CV] END ..C=10, max_iter=1000, penalty=l2, solver=liblinear; total time=   5.8s\n",
      "[CV] END ..C=10, max_iter=1000, penalty=l2, solver=liblinear; total time=   5.8s\n",
      "[CV] END ...C=1, max_iter=1000, penalty=l1, solver=liblinear; total time= 4.0min\n",
      "[CV] END ...C=1, max_iter=1000, penalty=l1, solver=liblinear; total time= 4.0min\n",
      "[CV] END ..C=10, max_iter=1000, penalty=l2, solver=liblinear; total time=   4.1s\n",
      "[CV] END ..C=10, max_iter=1000, penalty=l2, solver=liblinear; total time=   4.1s\n",
      "[CV] END ..C=10, max_iter=1000, penalty=l2, solver=liblinear; total time=   5.1s\n",
      "[CV] END ..C=10, max_iter=1000, penalty=l2, solver=liblinear; total time=   5.1s\n",
      "[CV] END ...C=1, max_iter=1000, penalty=l1, solver=liblinear; total time= 4.1min\n",
      "[CV] END ...C=1, max_iter=1000, penalty=l1, solver=liblinear; total time= 4.1min\n",
      "[CV] END .......C=10, max_iter=1000, penalty=l1, solver=saga; total time=  29.8s\n",
      "[CV] END .......C=10, max_iter=1000, penalty=l1, solver=saga; total time=  29.8s\n",
      "[CV] END .......C=10, max_iter=1000, penalty=l1, solver=saga; total time=  30.3s\n",
      "[CV] END .......C=10, max_iter=1000, penalty=l1, solver=saga; total time=  30.3s\n",
      "[CV] END .......C=10, max_iter=1000, penalty=l1, solver=saga; total time=  35.0s\n",
      "[CV] END ..C=10, max_iter=1000, penalty=l2, solver=liblinear; total time=   3.7s\n",
      "[CV] END .......C=10, max_iter=1000, penalty=l1, solver=saga; total time=  35.0s\n",
      "[CV] END ..C=10, max_iter=1000, penalty=l2, solver=liblinear; total time=   3.7s\n",
      "[CV] END ....C=1, max_iter=500, penalty=l1, solver=liblinear; total time= 4.9min\n",
      "[CV] END ....C=1, max_iter=500, penalty=l1, solver=liblinear; total time= 4.9min\n",
      "[CV] END ..C=10, max_iter=1000, penalty=l2, solver=liblinear; total time=   4.6s\n",
      "[CV] END ..C=10, max_iter=1000, penalty=l2, solver=liblinear; total time=   4.6s\n",
      "[CV] END .......C=10, max_iter=1000, penalty=l1, solver=saga; total time=  28.8s\n",
      "[CV] END .......C=10, max_iter=1000, penalty=l1, solver=saga; total time=  28.8s\n",
      "[CV] END ...C=1, max_iter=1000, penalty=l1, solver=liblinear; total time= 4.3min\n",
      "[CV] END ...C=1, max_iter=1000, penalty=l1, solver=liblinear; total time= 4.3min\n",
      "[CV] END .......C=10, max_iter=1000, penalty=l1, solver=saga; total time=  32.5s\n",
      "[CV] END .......C=10, max_iter=1000, penalty=l1, solver=saga; total time=  32.5s\n",
      "[CV] END .......C=10, max_iter=1000, penalty=l2, solver=saga; total time=  22.4s\n",
      "[CV] END .......C=10, max_iter=1000, penalty=l2, solver=saga; total time=  24.3s\n",
      "[CV] END .......C=10, max_iter=1000, penalty=l2, solver=saga; total time=  22.4s\n",
      "[CV] END .......C=10, max_iter=1000, penalty=l2, solver=saga; total time=  24.3s\n",
      "[CV] END .......C=10, max_iter=1000, penalty=l2, solver=saga; total time=  31.2s\n",
      "[CV] END .......C=10, max_iter=1000, penalty=l2, solver=saga; total time=  31.2s\n",
      "[CV] END .......C=10, max_iter=1000, penalty=l2, solver=saga; total time=  33.0s\n",
      "[CV] END .......C=10, max_iter=1000, penalty=l2, solver=saga; total time=  33.0s\n",
      "[CV] END ...C=10, max_iter=500, penalty=l1, solver=liblinear; total time= 4.1min\n",
      "[CV] END ...C=10, max_iter=500, penalty=l1, solver=liblinear; total time= 4.1min\n",
      "[CV] END .......C=10, max_iter=1000, penalty=l2, solver=saga; total time=  45.2s\n",
      "[CV] END .......C=10, max_iter=1000, penalty=l2, solver=saga; total time=  45.2s\n",
      "[CV] END ...C=10, max_iter=500, penalty=l1, solver=liblinear; total time= 4.2min\n",
      "[CV] END ...C=10, max_iter=500, penalty=l1, solver=liblinear; total time= 4.2min\n",
      "[CV] END ...C=10, max_iter=500, penalty=l1, solver=liblinear; total time= 4.3min\n",
      "[CV] END ...C=10, max_iter=500, penalty=l1, solver=liblinear; total time= 4.3min\n",
      "[CV] END ...C=10, max_iter=500, penalty=l1, solver=liblinear; total time= 4.3min\n",
      "[CV] END ...C=10, max_iter=500, penalty=l1, solver=liblinear; total time= 4.3min\n",
      "[CV] END ...C=10, max_iter=500, penalty=l1, solver=liblinear; total time= 4.3min\n",
      "[CV] END ...C=10, max_iter=500, penalty=l1, solver=liblinear; total time= 4.3min\n",
      "[CV] END ..C=10, max_iter=1000, penalty=l1, solver=liblinear; total time= 2.8min\n",
      "[CV] END ..C=10, max_iter=1000, penalty=l1, solver=liblinear; total time= 2.8min\n",
      "[CV] END ..C=10, max_iter=1000, penalty=l1, solver=liblinear; total time= 2.8min\n",
      "[CV] END ..C=10, max_iter=1000, penalty=l1, solver=liblinear; total time= 2.8min\n",
      "[CV] END ..C=10, max_iter=1000, penalty=l1, solver=liblinear; total time= 3.0min\n",
      "[CV] END ..C=10, max_iter=1000, penalty=l1, solver=liblinear; total time= 3.0min\n",
      "[CV] END ..C=10, max_iter=1000, penalty=l1, solver=liblinear; total time= 2.8min\n",
      "[CV] END ..C=10, max_iter=1000, penalty=l1, solver=liblinear; total time= 2.8min\n",
      "[CV] END ..C=10, max_iter=1000, penalty=l1, solver=liblinear; total time= 3.1min\n",
      "[CV] END ..C=10, max_iter=1000, penalty=l1, solver=liblinear; total time= 3.1min\n",
      "\n",
      "================================================================================\n",
      "Logistic Regression Results:\n",
      "================================================================================\n",
      "Best CV Score: 0.8292\n",
      "Best Parameters: {'C': 10, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Training Time: 621.98 seconds\n",
      "\n",
      "Top 5 Configurations:\n",
      "                                                                 params  mean_test_score  std_test_score\n",
      "32   {'C': 10, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear'}          0.82922        0.005234\n",
      "36  {'C': 10, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear'}          0.82922        0.005234\n",
      "26    {'C': 1, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear'}          0.82916        0.004947\n",
      "30   {'C': 1, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear'}          0.82916        0.004947\n",
      "17       {'C': 0.1, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga'}          0.82914        0.004682\n",
      "\n",
      "================================================================================\n",
      "Logistic Regression Results:\n",
      "================================================================================\n",
      "Best CV Score: 0.8292\n",
      "Best Parameters: {'C': 10, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Training Time: 621.98 seconds\n",
      "\n",
      "Top 5 Configurations:\n",
      "                                                                 params  mean_test_score  std_test_score\n",
      "32   {'C': 10, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear'}          0.82922        0.005234\n",
      "36  {'C': 10, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear'}          0.82922        0.005234\n",
      "26    {'C': 1, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear'}          0.82916        0.004947\n",
      "30   {'C': 1, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear'}          0.82916        0.004947\n",
      "17       {'C': 0.1, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga'}          0.82914        0.004682\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"1. LOGISTIC REGRESSION - Grid Search with 5-Fold CV\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Create model\n",
    "lr_model = LogisticRegression(random_state=42)\n",
    "\n",
    "# Grid search with cross-validation\n",
    "lr_grid = GridSearchCV(\n",
    "    estimator=lr_model,\n",
    "    param_grid=lr_param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "print(\"\\nFitting Logistic Regression...\")\n",
    "lr_grid.fit(X, y)\n",
    "\n",
    "lr_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"Logistic Regression Results:\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Best CV Score: {lr_grid.best_score_:.4f}\")\n",
    "print(f\"Best Parameters: {lr_grid.best_params_}\")\n",
    "print(f\"Training Time: {lr_time:.2f} seconds\")\n",
    "\n",
    "# Get top 5 results\n",
    "results_df = pd.DataFrame(lr_grid.cv_results_)\n",
    "top_5 = results_df.nlargest(5, 'mean_test_score')[['params', 'mean_test_score', 'std_test_score']]\n",
    "print(\"\\nTop 5 Configurations:\")\n",
    "print(top_5.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a77d20",
   "metadata": {},
   "source": [
    "## 5. Random Forest - GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8d5bdf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "2. RANDOM FOREST - Grid Search with 5-Fold CV\n",
      "================================================================================\n",
      "\n",
      "Fitting Random Forest...\n",
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=  35.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=  35.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=  35.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=  35.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=  36.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=  36.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=  37.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=  37.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=  37.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=  37.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=  34.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=  34.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=  34.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=  34.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time= 1.2min\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time= 1.2min\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=  35.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=  35.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=  35.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=  35.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time= 1.2min\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time= 1.2min\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time= 1.2min\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time= 1.2min\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time= 1.3min\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=  40.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time= 1.3min\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=  40.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time= 1.3min\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time= 1.3min\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time= 1.2min\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time= 1.2min\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time= 1.2min\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time= 1.2min\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time= 1.2min\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time= 1.2min\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time= 1.2min\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time= 1.2min\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time= 1.3min\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time= 1.3min\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time= 2.5min\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time= 2.5min\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time= 2.5min\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time= 2.5min\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time= 2.5min\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time= 2.5min\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time= 2.6min\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time= 2.6min\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time= 2.6min\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time= 2.6min\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=  34.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=  34.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=  35.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=  35.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=  40.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=  40.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=  40.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=  40.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=  40.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=  40.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time= 2.4min\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time= 2.4min\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 3.6min\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 3.6min\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 3.6min\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 3.6min\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 3.7min\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 3.7min\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time= 2.5min\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time= 2.5min\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 3.7min\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 3.7min\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time= 2.5min\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time= 2.5min\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 3.7min\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 3.7min\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time= 2.5min\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time= 2.5min\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time= 2.6min\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time= 2.6min\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time= 1.2min\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time= 1.2min\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time= 1.3min\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time= 1.3min\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time= 1.2min\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time= 1.2min\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time= 1.2min\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time= 1.2min\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time= 1.3min\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time= 1.3min\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=  37.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=  37.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=  37.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=  37.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=  39.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=  36.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=  39.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=  36.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=  40.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=  40.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 3.6min\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 3.6min\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 3.7min\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 3.7min\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time= 2.4min\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time= 2.5min\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time= 2.4min\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time= 2.5min\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 3.7min\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 3.7min\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time= 2.4min\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time= 2.4min\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 3.7min\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 3.7min\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time= 2.4min\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time= 1.2min\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time= 2.4min\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time= 1.2min\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time= 2.5min\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time= 2.5min\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time= 1.2min\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time= 1.2min\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 4.0min\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 4.0min\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time= 1.3min\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time= 1.3min\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time= 1.3min\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time= 1.3min\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time= 1.3min\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time= 1.3min\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=  49.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=  49.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=  52.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=  52.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=  55.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=  55.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=  57.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=  57.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=  58.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=  58.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 3.8min\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 3.8min\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 3.8min\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 3.8min\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 3.7min\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 3.7min\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 3.8min\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 3.8min\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 3.8min\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 3.8min\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     11\u001b[39m rf_grid = GridSearchCV(\n\u001b[32m     12\u001b[39m     estimator=rf_model,\n\u001b[32m     13\u001b[39m     param_grid=rf_param_grid,\n\u001b[32m   (...)\u001b[39m\u001b[32m     17\u001b[39m     verbose=\u001b[32m2\u001b[39m\n\u001b[32m     18\u001b[39m )\n\u001b[32m     20\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mFitting Random Forest...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[43mrf_grid\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m rf_time = time.time() - start_time\n\u001b[32m     25\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m=\u001b[39m\u001b[33m'\u001b[39m*\u001b[32m80\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/nlp/lib/python3.12/site-packages/sklearn/base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/nlp/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1051\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1045\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1046\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1047\u001b[39m     )\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1051\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1053\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1054\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1055\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/nlp/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1605\u001b[39m, in \u001b[36mGridSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1603\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1604\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1605\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/nlp/lib/python3.12/site-packages/sklearn/model_selection/_search.py:997\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    989\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose > \u001b[32m0\u001b[39m:\n\u001b[32m    990\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    991\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m candidates,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    992\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m fits\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    993\u001b[39m             n_splits, n_candidates, n_candidates * n_splits\n\u001b[32m    994\u001b[39m         )\n\u001b[32m    995\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m997\u001b[39m out = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    998\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    999\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1000\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1001\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1002\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1003\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1004\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1005\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1006\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1007\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1008\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) < \u001b[32m1\u001b[39m:\n\u001b[32m   1016\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1017\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo fits were performed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1018\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWas the CV iterator empty? \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1019\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWere there no candidates?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1020\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/nlp/lib/python3.12/site-packages/sklearn/utils/parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/nlp/lib/python3.12/site-packages/joblib/parallel.py:2072\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2070\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/nlp/lib/python3.12/site-packages/joblib/parallel.py:1682\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1688\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/nlp/lib/python3.12/site-packages/joblib/parallel.py:1800\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_ordered:\n\u001b[32m   1790\u001b[39m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[32m   1791\u001b[39m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1795\u001b[39m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[32m   1796\u001b[39m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[32m   1797\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1798\u001b[39m         \u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING\n\u001b[32m   1799\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1800\u001b[39m         \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1801\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1803\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs == \u001b[32m0\u001b[39m:\n\u001b[32m   1804\u001b[39m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[32m   1805\u001b[39m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1811\u001b[39m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[32m   1812\u001b[39m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"2. RANDOM FOREST - Grid Search with 5-Fold CV\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Create model\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Grid search with cross-validation\n",
    "rf_grid = GridSearchCV(\n",
    "    estimator=rf_model,\n",
    "    param_grid=rf_param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "print(\"\\nFitting Random Forest...\")\n",
    "rf_grid.fit(X, y)\n",
    "\n",
    "rf_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"Random Forest Results:\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Best CV Score: {rf_grid.best_score_:.4f}\")\n",
    "print(f\"Best Parameters: {rf_grid.best_params_}\")\n",
    "print(f\"Training Time: {rf_time:.2f} seconds ({rf_time/60:.2f} minutes)\")\n",
    "\n",
    "# Get top 5 results\n",
    "results_df = pd.DataFrame(rf_grid.cv_results_)\n",
    "top_5 = results_df.nlargest(5, 'mean_test_score')[['params', 'mean_test_score', 'std_test_score']]\n",
    "print(\"\\nTop 5 Configurations:\")\n",
    "print(top_5.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60d0405",
   "metadata": {},
   "source": [
    "## 6. AdaBoost - GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0072cf9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"3. ADABOOST - Grid Search with 5-Fold CV\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Create model\n",
    "ada_model = AdaBoostClassifier(random_state=42)\n",
    "\n",
    "# Grid search with cross-validation\n",
    "ada_grid = GridSearchCV(\n",
    "    estimator=ada_model,\n",
    "    param_grid=ada_param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "print(\"\\nFitting AdaBoost...\")\n",
    "ada_grid.fit(X, y)\n",
    "\n",
    "ada_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"AdaBoost Results:\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Best CV Score: {ada_grid.best_score_:.4f}\")\n",
    "print(f\"Best Parameters: {ada_grid.best_params_}\")\n",
    "print(f\"Training Time: {ada_time:.2f} seconds ({ada_time/60:.2f} minutes)\")\n",
    "\n",
    "# Get top 5 results\n",
    "results_df = pd.DataFrame(ada_grid.cv_results_)\n",
    "top_5 = results_df.nlargest(5, 'mean_test_score')[['params', 'mean_test_score', 'std_test_score']]\n",
    "print(\"\\nTop 5 Configurations:\")\n",
    "print(top_5.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53d3365",
   "metadata": {},
   "source": [
    "## 7. MLP (Neural Network) - GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0c74f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "4. MLP (Multi-Layer Perceptron) - Grid Search with 5-Fold CV\n",
      "================================================================================\n",
      "\n",
      "Fitting MLP...\n",
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=constant; total time=   3.9s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=constant; total time=   3.9s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=adaptive; total time=   4.2s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=adaptive; total time=   4.2s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=adaptive; total time=   4.1s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=adaptive; total time=   4.1s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=constant; total time=   4.5s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=constant; total time=   4.5s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=constant; total time=   6.2s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50, 50), learning_rate=constant; total time=   2.1s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=adaptive; total time=   6.2s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=adaptive; total time=   5.9s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=constant; total time=   5.7s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=constant; total time=   6.3s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50, 50), learning_rate=constant; total time=   2.3s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=adaptive; total time=   5.5s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=constant; total time=   6.2s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=constant; total time=   5.9s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=constant; total time=   6.2s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=constant; total time=   6.1s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50, 50), learning_rate=constant; total time=   1.3s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=adaptive; total time=   5.4s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=adaptive; total time=   5.4s[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=adaptive; total time=   6.1s\n",
      "\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=adaptive; total time=   5.2s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=constant; total time=   5.3s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=adaptive; total time=   5.6s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50, 50), learning_rate=constant; total time=   1.8s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=constant; total time=   6.2s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50, 50), learning_rate=constant; total time=   2.1s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=adaptive; total time=   6.2s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=adaptive; total time=   5.9s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=constant; total time=   5.7s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=constant; total time=   6.3s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50, 50), learning_rate=constant; total time=   2.3s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=adaptive; total time=   5.5s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=constant; total time=   6.2s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=constant; total time=   5.9s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=constant; total time=   6.2s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=constant; total time=   6.1s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50, 50), learning_rate=constant; total time=   1.3s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=adaptive; total time=   5.4s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=adaptive; total time=   5.4s[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=adaptive; total time=   6.1s\n",
      "\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=adaptive; total time=   5.2s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=constant; total time=   5.3s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=adaptive; total time=   5.6s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50, 50), learning_rate=constant; total time=   1.8s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     11\u001b[39m mlp_grid = GridSearchCV(\n\u001b[32m     12\u001b[39m     estimator=mlp_model,\n\u001b[32m     13\u001b[39m     param_grid=mlp_param_grid,\n\u001b[32m   (...)\u001b[39m\u001b[32m     17\u001b[39m     verbose=\u001b[32m2\u001b[39m\n\u001b[32m     18\u001b[39m )\n\u001b[32m     20\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mFitting MLP...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[43mmlp_grid\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m mlp_time = time.time() - start_time\n\u001b[32m     25\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m=\u001b[39m\u001b[33m'\u001b[39m*\u001b[32m80\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/nlp/lib/python3.12/site-packages/sklearn/base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/nlp/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1051\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1045\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1046\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1047\u001b[39m     )\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1051\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1053\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1054\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1055\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/nlp/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1605\u001b[39m, in \u001b[36mGridSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1603\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1604\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1605\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/nlp/lib/python3.12/site-packages/sklearn/model_selection/_search.py:997\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    989\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose > \u001b[32m0\u001b[39m:\n\u001b[32m    990\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    991\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m candidates,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    992\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m fits\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    993\u001b[39m             n_splits, n_candidates, n_candidates * n_splits\n\u001b[32m    994\u001b[39m         )\n\u001b[32m    995\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m997\u001b[39m out = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    998\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    999\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1000\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1001\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1002\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1003\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1004\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1005\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1006\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1007\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1008\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) < \u001b[32m1\u001b[39m:\n\u001b[32m   1016\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1017\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo fits were performed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1018\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWas the CV iterator empty? \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1019\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWere there no candidates?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1020\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/nlp/lib/python3.12/site-packages/sklearn/utils/parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/nlp/lib/python3.12/site-packages/joblib/parallel.py:2072\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2070\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/nlp/lib/python3.12/site-packages/joblib/parallel.py:1682\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1688\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/nlp/lib/python3.12/site-packages/joblib/parallel.py:1800\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_ordered:\n\u001b[32m   1790\u001b[39m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[32m   1791\u001b[39m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1795\u001b[39m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[32m   1796\u001b[39m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[32m   1797\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1798\u001b[39m         \u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING\n\u001b[32m   1799\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1800\u001b[39m         \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1801\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1803\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs == \u001b[32m0\u001b[39m:\n\u001b[32m   1804\u001b[39m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[32m   1805\u001b[39m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1811\u001b[39m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[32m   1812\u001b[39m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"4. MLP (Multi-Layer Perceptron) - Grid Search with 5-Fold CV\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Create model\n",
    "mlp_model = MLPClassifier(random_state=42, max_iter=500, early_stopping=True)\n",
    "\n",
    "# Grid search with cross-validation\n",
    "mlp_grid = GridSearchCV(\n",
    "    estimator=mlp_model,\n",
    "    param_grid=mlp_param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "print(\"\\nFitting MLP...\")\n",
    "mlp_grid.fit(X, y)\n",
    "\n",
    "mlp_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"MLP Results:\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Best CV Score: {mlp_grid.best_score_:.4f}\")\n",
    "print(f\"Best Parameters: {mlp_grid.best_params_}\")\n",
    "print(f\"Training Time: {mlp_time:.2f} seconds ({mlp_time/60:.2f} minutes)\")\n",
    "\n",
    "# Get top 5 results\n",
    "results_df = pd.DataFrame(mlp_grid.cv_results_)\n",
    "top_5 = results_df.nlargest(5, 'mean_test_score')[['params', 'mean_test_score', 'std_test_score']]\n",
    "print(\"\\nTop 5 Configurations:\")\n",
    "print(top_5.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b10a06",
   "metadata": {},
   "source": [
    "## 8. Compare All Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9390e7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of all models\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL COMPARISON - Best Models\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "comparison_data = [\n",
    "    {\n",
    "        'Model': 'Logistic Regression',\n",
    "        'Best CV Accuracy': lr_grid.best_score_,\n",
    "        'Training Time (s)': lr_time,\n",
    "        'Best Params': lr_grid.best_params_\n",
    "    },\n",
    "    {\n",
    "        'Model': 'Random Forest',\n",
    "        'Best CV Accuracy': rf_grid.best_score_,\n",
    "        'Training Time (s)': rf_time,\n",
    "        'Best Params': rf_grid.best_params_\n",
    "    },\n",
    "    {\n",
    "        'Model': 'AdaBoost',\n",
    "        'Best CV Accuracy': ada_grid.best_score_,\n",
    "        'Training Time (s)': ada_time,\n",
    "        'Best Params': ada_grid.best_params_\n",
    "    },\n",
    "    {\n",
    "        'Model': 'MLP (Neural Net)',\n",
    "        'Best CV Accuracy': mlp_grid.best_score_,\n",
    "        'Training Time (s)': mlp_time,\n",
    "        'Best Params': mlp_grid.best_params_\n",
    "    }\n",
    "]\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "comparison_df = comparison_df.sort_values('Best CV Accuracy', ascending=False)\n",
    "\n",
    "print(\"\\n\" + comparison_df[['Model', 'Best CV Accuracy', 'Training Time (s)']].to_string(index=False))\n",
    "\n",
    "# Find best model\n",
    "best_model_name = comparison_df.iloc[0]['Model']\n",
    "best_accuracy = comparison_df.iloc[0]['Best CV Accuracy']\n",
    "\n",
    "print(f\"\\n WINNER: {best_model_name}\")\n",
    "print(f\"   Accuracy: {best_accuracy:.4f} ({best_accuracy*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92346ab5",
   "metadata": {},
   "source": [
    "## 9. Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60fc385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot comparison\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Accuracy comparison\n",
    "models = comparison_df['Model'].values\n",
    "accuracies = comparison_df['Best CV Accuracy'].values\n",
    "colors = ['#3498db', '#e74c3c', '#2ecc71', '#f39c12']\n",
    "\n",
    "bars = ax1.bar(range(len(models)), accuracies, color=colors, alpha=0.7)\n",
    "ax1.set_xticks(range(len(models)))\n",
    "ax1.set_xticklabels(models, rotation=45, ha='right')\n",
    "ax1.set_ylabel('Cross-Validation Accuracy')\n",
    "ax1.set_title('Model Comparison - CV Accuracy')\n",
    "ax1.set_ylim([0.7, 1.0])\n",
    "ax1.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels\n",
    "for i, (bar, acc) in enumerate(zip(bars, accuracies)):\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2, acc + 0.01, \n",
    "             f'{acc:.4f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Training time comparison\n",
    "times = comparison_df['Training Time (s)'].values\n",
    "bars2 = ax2.bar(range(len(models)), times, color=colors, alpha=0.7)\n",
    "ax2.set_xticks(range(len(models)))\n",
    "ax2.set_xticklabels(models, rotation=45, ha='right')\n",
    "ax2.set_ylabel('Training Time (seconds)')\n",
    "ax2.set_title('Model Comparison - Training Time')\n",
    "ax2.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels\n",
    "for i, (bar, t) in enumerate(zip(bars2, times)):\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2, t + max(times)*0.02, \n",
    "             f'{t:.1f}s', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nVisualization complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7ca78e",
   "metadata": {},
   "source": [
    "## 10. Detailed Results for Each Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2fc9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot CV scores for each model\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "grids = [lr_grid, rf_grid, ada_grid, mlp_grid]\n",
    "titles = ['Logistic Regression', 'Random Forest', 'AdaBoost', 'MLP']\n",
    "colors_heat = ['Blues', 'Greens', 'Reds', 'Oranges']\n",
    "\n",
    "for idx, (grid, title, cmap) in enumerate(zip(grids, titles, colors_heat)):\n",
    "    results = pd.DataFrame(grid.cv_results_)\n",
    "    top_20 = results.nlargest(20, 'mean_test_score')\n",
    "    \n",
    "    # Plot top 20 configurations\n",
    "    x = range(len(top_20))\n",
    "    y = top_20['mean_test_score'].values\n",
    "    yerr = top_20['std_test_score'].values\n",
    "    \n",
    "    axes[idx].bar(x, y, alpha=0.6, color=plt.cm.get_cmap(cmap)(0.6))\n",
    "    axes[idx].errorbar(x, y, yerr=yerr, fmt='none', ecolor='black', alpha=0.5, capsize=3)\n",
    "    axes[idx].set_xlabel('Configuration Rank')\n",
    "    axes[idx].set_ylabel('CV Accuracy')\n",
    "    axes[idx].set_title(f'{title} - Top 20 Configurations')\n",
    "    axes[idx].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Highlight best\n",
    "    axes[idx].axhline(y=grid.best_score_, color='red', linestyle='--', \n",
    "                      label=f'Best: {grid.best_score_:.4f}', linewidth=2)\n",
    "    axes[idx].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Detailed results plotted!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8cfe63",
   "metadata": {},
   "source": [
    "## 11. Save Best Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f6582b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create output directory\n",
    "output_dir = '../../models/classifiers'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save best models\n",
    "models_to_save = [\n",
    "    ('logistic_regression_best.pkl', lr_grid.best_estimator_),\n",
    "    ('random_forest_best.pkl', rf_grid.best_estimator_),\n",
    "    ('adaboost_best.pkl', ada_grid.best_estimator_),\n",
    "    ('mlp_best.pkl', mlp_grid.best_estimator_)\n",
    "]\n",
    "\n",
    "print(\"Saving best models...\\n\")\n",
    "for filename, model in models_to_save:\n",
    "    path = os.path.join(output_dir, filename)\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "    print(f\" {filename}\")\n",
    "\n",
    "# Save comparison results\n",
    "comparison_df.to_csv(os.path.join(output_dir, 'model_comparison.csv'), index=False)\n",
    "print(f\"\\n model_comparison.csv\")\n",
    "\n",
    "# Save detailed results\n",
    "detailed_results = {\n",
    "    'logistic_regression': pd.DataFrame(lr_grid.cv_results_),\n",
    "    'random_forest': pd.DataFrame(rf_grid.cv_results_),\n",
    "    'adaboost': pd.DataFrame(ada_grid.cv_results_),\n",
    "    'mlp': pd.DataFrame(mlp_grid.cv_results_)\n",
    "}\n",
    "\n",
    "with pd.ExcelWriter(os.path.join(output_dir, 'detailed_results.xlsx')) as writer:\n",
    "    for name, df in detailed_results.items():\n",
    "        df.to_excel(writer, sheet_name=name, index=False)\n",
    "\n",
    "print(f\" detailed_results.xlsx\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"All models saved to: {output_dir}\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950c154b",
   "metadata": {},
   "source": [
    "## 12. Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5743961",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"HYPERPARAMETER TUNING SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\n Dataset: {X.shape[0]:,} samples, {X.shape[1]} features (Word2Vec embeddings)\")\n",
    "print(f\"\\n Cross-Validation: 5-fold\")\n",
    "print(f\"\\n  Models Tested: 4\")\n",
    "\n",
    "print(f\"\\n Results (sorted by accuracy):\\n\")\n",
    "for idx, row in comparison_df.iterrows():\n",
    "    print(f\"{idx+1}. {row['Model']:20s} - {row['Best CV Accuracy']:.4f} ({row['Best CV Accuracy']*100:.2f}%)\")\n",
    "\n",
    "print(f\"\\n Best Model: {best_model_name}\")\n",
    "print(f\"   CV Accuracy: {best_accuracy:.4f} ({best_accuracy*100:.2f}%)\")\n",
    "\n",
    "best_params = comparison_df[comparison_df['Model'] == best_model_name]['Best Params'].values[0]\n",
    "print(f\"   Best Parameters:\")\n",
    "for param, value in best_params.items():\n",
    "    print(f\"     - {param}: {value}\")\n",
    "\n",
    "total_time = lr_time + rf_time + ada_time + mlp_time\n",
    "print(f\"\\n  Total Training Time: {total_time:.2f} seconds ({total_time/60:.2f} minutes)\")\n",
    "\n",
    "print(f\"\\n Saved Files:\")\n",
    "print(f\"   - Best models: {output_dir}/*.pkl\")\n",
    "print(f\"   - Comparison: {output_dir}/model_comparison.csv\")\n",
    "print(f\"   - Details: {output_dir}/detailed_results.xlsx\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" Hyperparameter tuning complete!\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
