{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "264502e8",
   "metadata": {},
   "source": [
    "## 1. Install and Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0773e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install sentence-transformers (run once)\n",
    "# !pip install sentence-transformers -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669484ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "print(\"\\nLibraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03e91df",
   "metadata": {},
   "source": [
    "## 2. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9072ebb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "print(\"Loading dataset...\")\n",
    "df = pd.read_csv('../../data/cleaned_label.csv')\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "print(f\"\\nSentiment distribution:\")\n",
    "print(df['sentiment_label'].value_counts())\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e593039",
   "metadata": {},
   "source": [
    "## 3. Initialize SBERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ab5a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model name - SBERT all-MiniLM-L6-v2\n",
    "MODEL_NAME = 'all-MiniLM-L6-v2'\n",
    "\n",
    "print(f\"Loading SBERT model: {MODEL_NAME}\")\n",
    "print(\"Note: SBERT (Sentence-BERT) is optimized for sentence embeddings\")\n",
    "print(\"      - Uses siamese/triplet networks\")\n",
    "print(\"      - Produces semantically meaningful embeddings\")\n",
    "print(\"      - Faster than BERT for similarity tasks\")\n",
    "print(\"      - Only 22M parameters (very efficient!)\\n\")\n",
    "\n",
    "# Load model\n",
    "model = SentenceTransformer(MODEL_NAME)\n",
    "model = model.to(device)\n",
    "\n",
    "print(f\"Model loaded successfully!\")\n",
    "print(f\"Max sequence length: {model.max_seq_length}\")\n",
    "print(f\"Embedding dimension: {model.get_sentence_embedding_dimension()}\")\n",
    "print(f\"Number of parameters: ~22M (6 layers, 384 hidden size)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1ac40b",
   "metadata": {},
   "source": [
    "## 4. Extract Embeddings Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f45abc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sbert_embedding(text, model):\n",
    "    \"\"\"\n",
    "    Extract SBERT sentence embedding\n",
    "    \n",
    "    Args:\n",
    "        text: str - Input text\n",
    "        model: SentenceTransformer model\n",
    "        \n",
    "    Returns:\n",
    "        numpy array: 384-dimensional embedding vector\n",
    "    \"\"\"\n",
    "    # SBERT handles everything internally (tokenization, pooling, etc.)\n",
    "    embedding = model.encode(text, convert_to_numpy=True, show_progress_bar=False)\n",
    "    return embedding\n",
    "\n",
    "print(\"Embedding extraction function defined!\")\n",
    "\n",
    "# Test on sample texts\n",
    "sample_texts = [\n",
    "    \"This movie is absolutely fantastic!\",\n",
    "    \"This film is really great!\",\n",
    "    \"Terrible movie, waste of time.\"\n",
    "]\n",
    "\n",
    "print(\"\\nTesting with sample texts:\")\n",
    "embeddings_test = []\n",
    "for text in sample_texts:\n",
    "    emb = get_sbert_embedding(text, model)\n",
    "    embeddings_test.append(emb)\n",
    "    print(f\"  '{text}' -> shape: {emb.shape}\")\n",
    "\n",
    "# Check similarity between similar and different sentences\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "sim_similar = cosine_similarity([embeddings_test[0]], [embeddings_test[1]])[0][0]\n",
    "sim_different = cosine_similarity([embeddings_test[0]], [embeddings_test[2]])[0][0]\n",
    "\n",
    "print(f\"\\nSimilarity (fantastic vs great): {sim_similar:.4f}\")\n",
    "print(f\"Similarity (fantastic vs terrible): {sim_different:.4f}\")\n",
    "print(\"Note: SBERT captures semantic similarity!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4019d8c5",
   "metadata": {},
   "source": [
    "## 5. Extract Embeddings for All Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eda33e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "BATCH_SIZE = 64  # SBERT is efficient, can use larger batch size\n",
    "\n",
    "print(\"Extracting SBERT embeddings for all documents...\")\n",
    "print(f\"Model: {MODEL_NAME}\")\n",
    "print(f\"Batch size: {BATCH_SIZE}\")\n",
    "print(f\"Total documents: {len(df)}\\n\")\n",
    "\n",
    "# SBERT can process batches efficiently\n",
    "texts = df['review_text'].astype(str).tolist()\n",
    "\n",
    "# Encode all texts (SBERT handles batching internally)\n",
    "embeddings = model.encode(\n",
    "    texts,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    show_progress_bar=True,\n",
    "    convert_to_numpy=True\n",
    ")\n",
    "\n",
    "print(f\"\\nEmbeddings extracted!\")\n",
    "print(f\"Shape: {embeddings.shape}\")\n",
    "print(f\"Each document: {embeddings.shape[1]}-dimensional vector\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05390ee",
   "metadata": {},
   "source": [
    "## 6. Save Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c182e7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory\n",
    "output_dir = '../../models/sbert_embeddings'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save embeddings\n",
    "embeddings_path = os.path.join(output_dir, 'sbert_embeddings.npy')\n",
    "np.save(embeddings_path, embeddings)\n",
    "print(f\"Embeddings saved: {embeddings_path}\")\n",
    "\n",
    "# Save labels\n",
    "labels_path = os.path.join(output_dir, 'labels.npy')\n",
    "np.save(labels_path, df['sentiment_label'].values)\n",
    "print(f\"Labels saved: {labels_path}\")\n",
    "\n",
    "# Save metadata\n",
    "metadata = {\n",
    "    'model_name': MODEL_NAME,\n",
    "    'model_type': 'sentence-transformers',\n",
    "    'embedding_dimension': embeddings.shape[1],\n",
    "    'max_seq_length': model.max_seq_length,\n",
    "    'num_documents': len(embeddings),\n",
    "    'embedding_shape': embeddings.shape,\n",
    "    'pooling_mode': 'mean pooling',\n",
    "    'notes': 'SBERT optimized for semantic similarity, 384-dim output'\n",
    "}\n",
    "\n",
    "metadata_path = os.path.join(output_dir, 'metadata.pkl')\n",
    "with open(metadata_path, 'wb') as f:\n",
    "    pickle.dump(metadata, f)\n",
    "print(f\"Metadata saved: {metadata_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"All files saved successfully!\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nOutput directory: {output_dir}\")\n",
    "print(f\"Files:\")\n",
    "print(f\"  - sbert_embeddings.npy    (Embeddings: {embeddings.shape})\")\n",
    "print(f\"  - labels.npy              (Sentiment labels)\")\n",
    "print(f\"  - metadata.pkl            (Model metadata)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1789528e",
   "metadata": {},
   "source": [
    "## 7. Verify Saved Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc55e40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load saved embeddings\n",
    "print(\"Loading saved embeddings...\\n\")\n",
    "\n",
    "loaded_embeddings = np.load(embeddings_path)\n",
    "loaded_labels = np.load(labels_path)\n",
    "\n",
    "with open(metadata_path, 'rb') as f:\n",
    "    loaded_metadata = pickle.load(f)\n",
    "\n",
    "print(f\"‚úì Embeddings loaded: {loaded_embeddings.shape}\")\n",
    "print(f\"‚úì Labels loaded: {loaded_labels.shape}\")\n",
    "print(f\"\\n‚úì Metadata:\")\n",
    "for key, value in loaded_metadata.items():\n",
    "    print(f\"    {key}: {value}\")\n",
    "\n",
    "# Verify integrity\n",
    "print(f\"\\n‚úì Verification:\")\n",
    "print(f\"    Embeddings match: {np.allclose(embeddings, loaded_embeddings)}\")\n",
    "print(f\"    Labels match: {np.array_equal(df['sentiment_label'].values, loaded_labels)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb64b7e2",
   "metadata": {},
   "source": [
    "## 8. Embedding Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9e6e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"Embedding Statistics:\\n\")\n",
    "\n",
    "# Basic stats\n",
    "print(f\"Shape: {embeddings.shape}\")\n",
    "print(f\"Mean: {embeddings.mean():.4f}\")\n",
    "print(f\"Std: {embeddings.std():.4f}\")\n",
    "print(f\"Min: {embeddings.min():.4f}\")\n",
    "print(f\"Max: {embeddings.max():.4f}\")\n",
    "\n",
    "# Plot distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Overall distribution\n",
    "axes[0].hist(embeddings.flatten(), bins=100, alpha=0.7, color='purple')\n",
    "axes[0].set_xlabel('Embedding Value')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('SBERT Embedding Value Distribution')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Mean embedding per document\n",
    "mean_embeddings = embeddings.mean(axis=1)\n",
    "axes[1].hist(mean_embeddings, bins=50, alpha=0.7, color='orange')\n",
    "axes[1].set_xlabel('Mean Embedding Value')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].set_title('Mean Embedding per Document')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nStatistics plotted!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afab1ad",
   "metadata": {},
   "source": [
    "## 9. Compare Positive vs Negative Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d95e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Sample for visualization\n",
    "sample_size = 1000\n",
    "indices = np.random.choice(len(embeddings), size=min(sample_size, len(embeddings)), replace=False)\n",
    "\n",
    "sample_embeddings = embeddings[indices]\n",
    "sample_labels = df['sentiment_label'].iloc[indices].values\n",
    "\n",
    "# PCA reduction to 2D\n",
    "print(f\"Performing PCA on {len(sample_embeddings)} samples...\")\n",
    "pca = PCA(n_components=2)\n",
    "embeddings_2d = pca.fit_transform(sample_embeddings)\n",
    "\n",
    "print(f\"Explained variance: {pca.explained_variance_ratio_.sum():.2%}\")\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "scatter = plt.scatter(\n",
    "    embeddings_2d[:, 0],\n",
    "    embeddings_2d[:, 1],\n",
    "    c=sample_labels,\n",
    "    cmap='RdYlGn',\n",
    "    alpha=0.6,\n",
    "    s=30\n",
    ")\n",
    "plt.colorbar(scatter, label='Sentiment (0=Neg, 1=Pos)')\n",
    "plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%} variance)')\n",
    "plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%} variance)')\n",
    "plt.title('SBERT Embeddings Visualization (PCA)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nVisualization complete!\")\n",
    "print(\"Note: SBERT embeddings should show better semantic clustering!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2614a6e",
   "metadata": {},
   "source": [
    "## 10. Semantic Similarity Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371bd5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find most similar reviews to a query\n",
    "print(\"Testing semantic similarity search:\\n\")\n",
    "\n",
    "# Query review\n",
    "query_idx = 0\n",
    "query_text = df['review_text'].iloc[query_idx]\n",
    "query_embedding = embeddings[query_idx]\n",
    "\n",
    "print(f\"Query review: '{query_text[:200]}...'\")\n",
    "print(f\"Query sentiment: {['Negative', 'Positive'][df['sentiment_label'].iloc[query_idx]]}\\n\")\n",
    "\n",
    "# Compute similarities\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "similarities = cosine_similarity([query_embedding], embeddings)[0]\n",
    "\n",
    "# Get top 5 most similar (excluding itself)\n",
    "top_indices = np.argsort(similarities)[::-1][1:6]\n",
    "\n",
    "print(\"Top 5 most similar reviews:\")\n",
    "print(\"=\"*80)\n",
    "for i, idx in enumerate(top_indices, 1):\n",
    "    similar_text = df['review_text'].iloc[idx]\n",
    "    similar_label = df['sentiment_label'].iloc[idx]\n",
    "    similarity = similarities[idx]\n",
    "    \n",
    "    print(f\"\\n{i}. Similarity: {similarity:.4f} | Sentiment: {['Neg', 'Pos'][similar_label]}\")\n",
    "    print(f\"   Text: '{similar_text[:150]}...'\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SBERT captures semantic meaning, not just word overlap!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa676c49",
   "metadata": {},
   "source": [
    "## 11. SBERT vs BERT Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efd21c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SBERT vs BERT Comparison\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "comparison = {\n",
    "    'Feature': [\n",
    "        'Purpose',\n",
    "        'Training',\n",
    "        'Architecture',\n",
    "        'Embedding Dimension',\n",
    "        'Parameters',\n",
    "        'Pooling Strategy',\n",
    "        'Semantic Similarity',\n",
    "        'Speed',\n",
    "        'Use Case'\n",
    "    ],\n",
    "    'BERT': [\n",
    "        'General NLP',\n",
    "        'Masked LM + NSP',\n",
    "        'Transformer encoder',\n",
    "        '768 (base)',\n",
    "        '110M (base)',\n",
    "        '[CLS] token',\n",
    "        'Not optimized',\n",
    "        'Slower',\n",
    "        'Classification, NER, QA'\n",
    "    ],\n",
    "    'SBERT (all-MiniLM-L6-v2)': [\n",
    "        'Sentence embeddings',\n",
    "        'Siamese/Triplet networks',\n",
    "        'Transformer (6 layers)',\n",
    "        '384',\n",
    "        '22M',\n",
    "        'Mean pooling',\n",
    "        'Highly optimized',\n",
    "        'Much faster',\n",
    "        'Similarity, clustering, retrieval'\n",
    "    ]\n",
    "}\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison)\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Key Advantages of SBERT:\")\n",
    "print(\"=\"*80)\n",
    "print(\"1. 5x smaller (22M vs 110M parameters)\")\n",
    "print(\"2. Produces semantically meaningful embeddings\")\n",
    "print(\"3. Much faster for similarity tasks (no need to compare all pairs)\")\n",
    "print(\"4. Lower dimensional (384 vs 768) - saves memory\")\n",
    "print(\"5. Pre-trained on similarity tasks (NLI, STS)\")\n",
    "print(\"\\nResult: SBERT is best for sentence embeddings & similarity tasks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388a8c91",
   "metadata": {},
   "source": [
    "## 12. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aea5690",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SBERT (SENTENCE-BERT) EMBEDDING EXTRACTION SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nüìä Model: {MODEL_NAME}\")\n",
    "print(f\"üöÄ Architecture: Sentence-BERT (optimized for sentence embeddings)\")\n",
    "print(f\"üìè Embedding dimension: {embeddings.shape[1]} (smaller than BERT!)\")\n",
    "print(f\"üìÅ Total documents: {embeddings.shape[0]:,}\")\n",
    "print(f\"üíæ Total size: {embeddings.nbytes / (1024**2):.2f} MB\")\n",
    "print(f\"‚ö° Parameters: Only 22M (5x smaller than BERT Base)\")\n",
    "\n",
    "print(f\"\\n‚úÖ Files saved:\")\n",
    "print(f\"   {output_dir}/\")\n",
    "print(f\"   ‚îú‚îÄ‚îÄ sbert_embeddings.npy  ({embeddings.shape})\")\n",
    "print(f\"   ‚îú‚îÄ‚îÄ labels.npy            ({loaded_labels.shape})\")\n",
    "print(f\"   ‚îî‚îÄ‚îÄ metadata.pkl\")\n",
    "\n",
    "print(f\"\\nüí° Usage:\")\n",
    "print(f\"   These embeddings can be used with any classifier:\")\n",
    "print(f\"   - Logistic Regression\")\n",
    "print(f\"   - SVM\")\n",
    "print(f\"   - Random Forest\")\n",
    "print(f\"   - K-Means clustering\")\n",
    "print(f\"   - Semantic search\")\n",
    "\n",
    "print(f\"\\nüîß Load embeddings:\")\n",
    "print(f\"   X = np.load('{embeddings_path}')\")\n",
    "print(f\"   y = np.load('{labels_path}')\")\n",
    "\n",
    "print(f\"\\n‚ö° Why SBERT:\")\n",
    "print(f\"   - Optimized for semantic similarity\")\n",
    "print(f\"   - Much smaller and faster than BERT\")\n",
    "print(f\"   - Produces meaningful sentence embeddings\")\n",
    "print(f\"   - Best for: similarity search, clustering, retrieval\")\n",
    "print(f\"   - Lower dimensional embeddings (saves memory & computation)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ SBERT embedding extraction complete!\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
