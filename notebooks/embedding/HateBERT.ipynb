{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd977615",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e627f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "print(\"\\nLibraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bbba3b",
   "metadata": {},
   "source": [
    "## 2. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55a68cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "print(\"Loading dataset...\")\n",
    "df = pd.read_csv('../../data/cleaned_label.csv')\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "print(f\"\\nSentiment distribution:\")\n",
    "print(df['sentiment_label'].value_counts())\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d42e93",
   "metadata": {},
   "source": [
    "## 3. Initialize HateBERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4c4199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model name - HateBERT\n",
    "MODEL_NAME = 'GroNLP/hateBERT'\n",
    "\n",
    "print(f\"Loading HateBERT model: {MODEL_NAME}\")\n",
    "print(\"Note: HateBERT is BERT re-trained on offensive/abusive content\")\n",
    "print(\"      - Based on BERT-base architecture\")\n",
    "print(\"      - Pre-trained on Reddit banned communities (1.5M posts)\")\n",
    "print(\"      - Specialized for hate speech, offensive language, abuse\")\n",
    "print(\"      - Better at understanding toxic/negative sentiment\")\n",
    "print(\"      - May capture subtle negative nuances better\\n\")\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = BertModel.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# Move to device\n",
    "model = model.to(device)\n",
    "model.eval()  # Set to evaluation mode\n",
    "\n",
    "print(f\"Model loaded successfully!\")\n",
    "print(f\"Vocabulary size: {tokenizer.vocab_size}\")\n",
    "print(f\"Hidden size: {model.config.hidden_size}\")\n",
    "print(f\"Number of layers: {model.config.num_hidden_layers}\")\n",
    "print(f\"Number of attention heads: {model.config.num_attention_heads}\")\n",
    "print(f\"Total parameters: ~110M (same as BERT-base)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f832536a",
   "metadata": {},
   "source": [
    "## 4. Extract Embeddings Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0172269e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hatebert_embedding(text, tokenizer, model, device, max_length=128):\n",
    "    \"\"\"\n",
    "    Extract HateBERT [CLS] token embedding\n",
    "    \n",
    "    Args:\n",
    "        text: str - Input text\n",
    "        tokenizer: HateBERT tokenizer\n",
    "        model: HateBERT model\n",
    "        device: torch device\n",
    "        max_length: int - Max sequence length\n",
    "        \n",
    "    Returns:\n",
    "        numpy array: 768-dimensional embedding vector\n",
    "    \"\"\"\n",
    "    # Tokenize\n",
    "    encoding = tokenizer.encode_plus(\n",
    "        text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=max_length,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    input_ids = encoding['input_ids'].to(device)\n",
    "    attention_mask = encoding['attention_mask'].to(device)\n",
    "    \n",
    "    # Get embeddings\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        # Extract [CLS] token embedding (first token)\n",
    "        cls_embedding = outputs.last_hidden_state[:, 0, :]\n",
    "    \n",
    "    return cls_embedding.cpu().numpy().flatten()\n",
    "\n",
    "print(\"Embedding extraction function defined!\")\n",
    "\n",
    "# Test on sample texts (including negative sentiment)\n",
    "sample_texts = [\n",
    "    \"This movie is absolutely fantastic!\",\n",
    "    \"Terrible waste of time, complete garbage.\",\n",
    "    \"I absolutely hated this movie, worst ever.\"\n",
    "]\n",
    "\n",
    "print(\"\\nTesting with sample texts:\")\n",
    "for text in sample_texts:\n",
    "    embedding = get_hatebert_embedding(text, tokenizer, model, device)\n",
    "    print(f\"  '{text}' -> shape: {embedding.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d073e366",
   "metadata": {},
   "source": [
    "## 5. Extract Embeddings for All Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362d2ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "MAX_LENGTH = 128\n",
    "BATCH_SIZE = 32  # Process in batches to save memory\n",
    "\n",
    "print(\"Extracting HateBERT embeddings for all documents...\")\n",
    "print(f\"Model: {MODEL_NAME}\")\n",
    "print(f\"Max length: {MAX_LENGTH}\")\n",
    "print(f\"Batch size: {BATCH_SIZE}\")\n",
    "print(f\"Total documents: {len(df)}\\n\")\n",
    "print(\"Note: HateBERT may capture negative sentiment nuances better\")\n",
    "print(\"      due to training on offensive/toxic content\\n\")\n",
    "\n",
    "embeddings = []\n",
    "\n",
    "# Process in batches\n",
    "for i in tqdm(range(0, len(df), BATCH_SIZE)):\n",
    "    batch_texts = df['review_text'].iloc[i:i+BATCH_SIZE].values\n",
    "    \n",
    "    for text in batch_texts:\n",
    "        embedding = get_hatebert_embedding(str(text), tokenizer, model, device, MAX_LENGTH)\n",
    "        embeddings.append(embedding)\n",
    "\n",
    "# Convert to numpy array\n",
    "embeddings = np.array(embeddings)\n",
    "\n",
    "print(f\"\\nEmbeddings extracted!\")\n",
    "print(f\"Shape: {embeddings.shape}\")\n",
    "print(f\"Each document: {embeddings.shape[1]}-dimensional vector\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d70adab",
   "metadata": {},
   "source": [
    "## 6. Save Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cbbd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory\n",
    "output_dir = '../../models/hatebert_embeddings'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save embeddings\n",
    "embeddings_path = os.path.join(output_dir, 'hatebert_embeddings.npy')\n",
    "np.save(embeddings_path, embeddings)\n",
    "print(f\"Embeddings saved: {embeddings_path}\")\n",
    "\n",
    "# Save labels\n",
    "labels_path = os.path.join(output_dir, 'labels.npy')\n",
    "np.save(labels_path, df['sentiment_label'].values)\n",
    "print(f\"Labels saved: {labels_path}\")\n",
    "\n",
    "# Save metadata\n",
    "metadata = {\n",
    "    'model_name': MODEL_NAME,\n",
    "    'model_type': 'hateBERT (BERT-base retrained)',\n",
    "    'hidden_size': model.config.hidden_size,\n",
    "    'max_length': MAX_LENGTH,\n",
    "    'num_documents': len(embeddings),\n",
    "    'embedding_shape': embeddings.shape,\n",
    "    'extraction_method': '[CLS] token from last_hidden_state',\n",
    "    'training_data': 'Reddit banned communities (1.5M posts)',\n",
    "    'specialization': 'Hate speech, offensive language, toxic content',\n",
    "    'notes': 'May perform better on negative/toxic sentiment due to specialized training'\n",
    "}\n",
    "\n",
    "metadata_path = os.path.join(output_dir, 'metadata.pkl')\n",
    "with open(metadata_path, 'wb') as f:\n",
    "    pickle.dump(metadata, f)\n",
    "print(f\"Metadata saved: {metadata_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"All files saved successfully!\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nOutput directory: {output_dir}\")\n",
    "print(f\"Files:\")\n",
    "print(f\"  - hatebert_embeddings.npy    (Embeddings: {embeddings.shape})\")\n",
    "print(f\"  - labels.npy                 (Sentiment labels)\")\n",
    "print(f\"  - metadata.pkl               (Model metadata)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1417711e",
   "metadata": {},
   "source": [
    "## 7. Verify Saved Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a93960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load saved embeddings\n",
    "print(\"Loading saved embeddings...\\n\")\n",
    "\n",
    "loaded_embeddings = np.load(embeddings_path)\n",
    "loaded_labels = np.load(labels_path)\n",
    "\n",
    "with open(metadata_path, 'rb') as f:\n",
    "    loaded_metadata = pickle.load(f)\n",
    "\n",
    "print(f\"‚úì Embeddings loaded: {loaded_embeddings.shape}\")\n",
    "print(f\"‚úì Labels loaded: {loaded_labels.shape}\")\n",
    "print(f\"\\n‚úì Metadata:\")\n",
    "for key, value in loaded_metadata.items():\n",
    "    print(f\"    {key}: {value}\")\n",
    "\n",
    "# Verify integrity\n",
    "print(f\"\\n‚úì Verification:\")\n",
    "print(f\"    Embeddings match: {np.allclose(embeddings, loaded_embeddings)}\")\n",
    "print(f\"    Labels match: {np.array_equal(df['sentiment_label'].values, loaded_labels)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fc78ce",
   "metadata": {},
   "source": [
    "## 8. Embedding Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371584f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"Embedding Statistics:\\n\")\n",
    "\n",
    "# Basic stats\n",
    "print(f\"Shape: {embeddings.shape}\")\n",
    "print(f\"Mean: {embeddings.mean():.4f}\")\n",
    "print(f\"Std: {embeddings.std():.4f}\")\n",
    "print(f\"Min: {embeddings.min():.4f}\")\n",
    "print(f\"Max: {embeddings.max():.4f}\")\n",
    "\n",
    "# Plot distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Overall distribution\n",
    "axes[0].hist(embeddings.flatten(), bins=100, alpha=0.7, color='darkred')\n",
    "axes[0].set_xlabel('Embedding Value')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('HateBERT Embedding Value Distribution')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Mean embedding per document\n",
    "mean_embeddings = embeddings.mean(axis=1)\n",
    "axes[1].hist(mean_embeddings, bins=50, alpha=0.7, color='maroon')\n",
    "axes[1].set_xlabel('Mean Embedding Value')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].set_title('Mean Embedding per Document')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nStatistics plotted!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c5c443",
   "metadata": {},
   "source": [
    "## 9. Compare Positive vs Negative Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fff9123",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Sample for visualization\n",
    "sample_size = 1000\n",
    "indices = np.random.choice(len(embeddings), size=min(sample_size, len(embeddings)), replace=False)\n",
    "\n",
    "sample_embeddings = embeddings[indices]\n",
    "sample_labels = df['sentiment_label'].iloc[indices].values\n",
    "\n",
    "# PCA reduction to 2D\n",
    "print(f\"Performing PCA on {len(sample_embeddings)} samples...\")\n",
    "pca = PCA(n_components=2)\n",
    "embeddings_2d = pca.fit_transform(sample_embeddings)\n",
    "\n",
    "print(f\"Explained variance: {pca.explained_variance_ratio_.sum():.2%}\")\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "scatter = plt.scatter(\n",
    "    embeddings_2d[:, 0],\n",
    "    embeddings_2d[:, 1],\n",
    "    c=sample_labels,\n",
    "    cmap='RdYlGn',\n",
    "    alpha=0.6,\n",
    "    s=30\n",
    ")\n",
    "plt.colorbar(scatter, label='Sentiment (0=Neg, 1=Pos)')\n",
    "plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%} variance)')\n",
    "plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%} variance)')\n",
    "plt.title('HateBERT Embeddings Visualization (PCA)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nVisualization complete!\")\n",
    "print(\"Note: HateBERT may show better separation for negative sentiment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbeefdc",
   "metadata": {},
   "source": [
    "## 10. Negative Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2718a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze negative sentiment embeddings\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Negative Sentiment Analysis\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "neg_indices = df[df['sentiment_label'] == 0].index\n",
    "pos_indices = df[df['sentiment_label'] == 1].index\n",
    "\n",
    "neg_embeddings = embeddings[neg_indices]\n",
    "pos_embeddings = embeddings[pos_indices]\n",
    "\n",
    "print(f\"\\nNegative reviews: {len(neg_embeddings):,}\")\n",
    "print(f\"Positive reviews: {len(pos_embeddings):,}\")\n",
    "\n",
    "print(f\"\\nNegative embedding stats:\")\n",
    "print(f\"  Mean: {neg_embeddings.mean():.4f}\")\n",
    "print(f\"  Std: {neg_embeddings.std():.4f}\")\n",
    "\n",
    "print(f\"\\nPositive embedding stats:\")\n",
    "print(f\"  Mean: {pos_embeddings.mean():.4f}\")\n",
    "print(f\"  Std: {pos_embeddings.std():.4f}\")\n",
    "\n",
    "# Compare distribution\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(neg_embeddings.mean(axis=1), bins=50, alpha=0.6, label='Negative', color='red')\n",
    "plt.hist(pos_embeddings.mean(axis=1), bins=50, alpha=0.6, label='Positive', color='green')\n",
    "plt.xlabel('Mean Embedding Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('HateBERT: Mean Embedding Distribution by Sentiment')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.boxplot([neg_embeddings.mean(axis=1), pos_embeddings.mean(axis=1)],\n",
    "            labels=['Negative', 'Positive'])\n",
    "plt.ylabel('Mean Embedding Value')\n",
    "plt.title('HateBERT: Embedding Comparison by Sentiment')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nHateBERT's training on toxic content may provide better negative sentiment representation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6536ccc6",
   "metadata": {},
   "source": [
    "## 11. HateBERT vs BERT Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6867396a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"HateBERT vs BERT Comparison\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "comparison = {\n",
    "    'Feature': [\n",
    "        'Base Architecture',\n",
    "        'Parameters',\n",
    "        'Hidden Size',\n",
    "        'Training Data',\n",
    "        'Training Domain',\n",
    "        'Specialization',\n",
    "        'Best For',\n",
    "        'Vocabulary',\n",
    "        'Performance'\n",
    "    ],\n",
    "    'BERT': [\n",
    "        'BERT-base',\n",
    "        '110M',\n",
    "        '768',\n",
    "        'BookCorpus + Wikipedia',\n",
    "        'General text (clean)',\n",
    "        'General NLP',\n",
    "        'General tasks',\n",
    "        'Standard English',\n",
    "        'Good overall'\n",
    "    ],\n",
    "    'HateBERT': [\n",
    "        'BERT-base (re-trained)',\n",
    "        '110M',\n",
    "        '768',\n",
    "        'Reddit banned communities',\n",
    "        'Offensive/toxic content',\n",
    "        'Hate speech, abuse',\n",
    "        'Toxic/negative content',\n",
    "        'Includes slang, offensive terms',\n",
    "        'Better on toxic/negative text'\n",
    "    ]\n",
    "}\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison)\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Why HateBERT for Sentiment Analysis:\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\n1. Negative Sentiment Understanding:\")\n",
    "print(\"   - Trained on offensive/toxic content from Reddit\")\n",
    "print(\"   - Better at capturing subtle negative nuances\")\n",
    "print(\"   - Understands slang, informal negative expressions\")\n",
    "\n",
    "print(\"\\n2. Movie Reviews Context:\")\n",
    "print(\"   - Reviews can be harsh/critical (similar to toxic content)\")\n",
    "print(\"   - Informal language, strong opinions\")\n",
    "print(\"   - May capture extreme negative sentiment better\")\n",
    "\n",
    "print(\"\\n3. Vocabulary:\")\n",
    "print(\"   - Includes offensive/slang terms not in standard BERT\")\n",
    "print(\"   - Better coverage of negative expressions\")\n",
    "print(\"   - More robust to informal/harsh language\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Note: Despite the name, HateBERT can be used for any sentiment analysis!\")\n",
    "print(\"The toxic training data gives it better negative sentiment understanding.\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247df6d3",
   "metadata": {},
   "source": [
    "## 12. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae6ca89",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"HateBERT EMBEDDING EXTRACTION SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nüìä Model: {MODEL_NAME}\")\n",
    "print(f\"üöÄ Architecture: BERT-base re-trained on toxic content\")\n",
    "print(f\"üìè Embedding dimension: {embeddings.shape[1]}\")\n",
    "print(f\"üìÅ Total documents: {embeddings.shape[0]:,}\")\n",
    "print(f\"üíæ Total size: {embeddings.nbytes / (1024**2):.2f} MB\")\n",
    "print(f\"‚ö° Parameters: 110M (same as BERT-base)\")\n",
    "\n",
    "print(f\"\\n‚úÖ Files saved:\")\n",
    "print(f\"   {output_dir}/\")\n",
    "print(f\"   ‚îú‚îÄ‚îÄ hatebert_embeddings.npy  ({embeddings.shape})\")\n",
    "print(f\"   ‚îú‚îÄ‚îÄ labels.npy               ({loaded_labels.shape})\")\n",
    "print(f\"   ‚îî‚îÄ‚îÄ metadata.pkl\")\n",
    "\n",
    "print(f\"\\nüí° Usage:\")\n",
    "print(f\"   These embeddings can be used with any classifier:\")\n",
    "print(f\"   - Logistic Regression\")\n",
    "print(f\"   - SVM\")\n",
    "print(f\"   - Random Forest\")\n",
    "print(f\"   - Neural Networks\")\n",
    "\n",
    "print(f\"\\nüîß Load embeddings:\")\n",
    "print(f\"   X = np.load('{embeddings_path}')\")\n",
    "print(f\"   y = np.load('{labels_path}')\")\n",
    "\n",
    "print(f\"\\n‚ö° Why HateBERT:\")\n",
    "print(f\"   - Trained on 1.5M Reddit posts from banned communities\")\n",
    "print(f\"   - Specialized for offensive/toxic content\")\n",
    "print(f\"   - Better understanding of negative sentiment nuances\")\n",
    "print(f\"   - Includes slang and informal vocabulary\")\n",
    "print(f\"   - May outperform standard BERT on harsh/critical reviews\")\n",
    "print(f\"   - Good for capturing extreme negative sentiment\")\n",
    "\n",
    "print(f\"\\nüéØ Expected Advantage:\")\n",
    "print(f\"   - Better at detecting subtle negative sentiment\")\n",
    "print(f\"   - More robust to informal/harsh language\")\n",
    "print(f\"   - May improve negative review classification\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ HateBERT embedding extraction complete!\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
