{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f554a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required libraries (run once)\n",
    "# !pip install sentence-transformers torch scikit-learn -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42d2a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer, InputExample, losses\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# Set random seeds\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Check GPU availability\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "print(\"\\nLibraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949b098c",
   "metadata": {},
   "source": [
    "## 2. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82ad04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "print(\"Loading dataset...\")\n",
    "df = pd.read_csv('../data/cleaned_label.csv')\n",
    "\n",
    "# Sample subset for faster training (optional - uncomment to use)\n",
    "# df = df.sample(n=5000, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "print(f\"\\nSentiment distribution:\")\n",
    "print(df['sentiment_label'].value_counts())\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deafb593",
   "metadata": {},
   "source": [
    "## 3. Initialize SBERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558da0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SBERT model\n",
    "MODEL_NAME = 'all-MiniLM-L6-v2'\n",
    "\n",
    "print(f\"Loading SBERT model: {MODEL_NAME}\")\n",
    "model = SentenceTransformer(MODEL_NAME)\n",
    "\n",
    "print(f\"Model loaded successfully!\")\n",
    "print(f\"Max sequence length: {model.max_seq_length}\")\n",
    "print(f\"Embedding dimension: {model.get_sentence_embedding_dimension()}\")\n",
    "\n",
    "# Test model\n",
    "sample_text = \"This movie is absolutely fantastic!\"\n",
    "embedding = model.encode(sample_text)\n",
    "print(f\"\\nSample text: {sample_text}\")\n",
    "print(f\"Embedding shape: {embedding.shape}\")\n",
    "print(f\"Embedding preview (first 10 values): {embedding[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e8f5c0",
   "metadata": {},
   "source": [
    "## 4. Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd4a9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['review_text'].values,\n",
    "    df['sentiment_label'].values,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=df['sentiment_label'].values\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Testing samples: {len(X_test)}\")\n",
    "print(f\"\\nTrain label distribution:\")\n",
    "print(pd.Series(y_train).value_counts())\n",
    "print(f\"\\nTest label distribution:\")\n",
    "print(pd.Series(y_test).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02227ce8",
   "metadata": {},
   "source": [
    "## 5. Generate Sentence Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc082b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embeddings\n",
    "print(\"Generating sentence embeddings...\")\n",
    "print(\"This may take a few minutes...\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Encode training data\n",
    "print(\"Encoding training data...\")\n",
    "train_embeddings = model.encode(\n",
    "    X_train.tolist(),\n",
    "    batch_size=32,\n",
    "    show_progress_bar=True,\n",
    "    convert_to_numpy=True\n",
    ")\n",
    "\n",
    "# Encode test data\n",
    "print(\"\\nEncoding test data...\")\n",
    "test_embeddings = model.encode(\n",
    "    X_test.tolist(),\n",
    "    batch_size=32,\n",
    "    show_progress_bar=True,\n",
    "    convert_to_numpy=True\n",
    ")\n",
    "\n",
    "embedding_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\nEmbedding generation completed in {embedding_time:.2f} seconds ({embedding_time/60:.2f} minutes)\")\n",
    "print(f\"Train embeddings shape: {train_embeddings.shape}\")\n",
    "print(f\"Test embeddings shape: {test_embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00685b84",
   "metadata": {},
   "source": [
    "## 6. Train Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42068740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Logistic Regression classifier on embeddings\n",
    "print(\"Training Logistic Regression classifier...\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "classifier = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    random_state=42,\n",
    "    C=1.0,\n",
    "    solver='lbfgs'\n",
    ")\n",
    "\n",
    "classifier.fit(train_embeddings, y_train)\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\nClassifier training completed in {training_time:.2f} seconds\")\n",
    "print(f\"Classifier: {classifier}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa406018",
   "metadata": {},
   "source": [
    "## 7. Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf32b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "print(\"Evaluating model...\\n\")\n",
    "\n",
    "# Training accuracy\n",
    "train_predictions = classifier.predict(train_embeddings)\n",
    "train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "\n",
    "# Test accuracy\n",
    "test_predictions = classifier.predict(test_embeddings)\n",
    "test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(f\"Training Accuracy: {train_accuracy:.4f} ({train_accuracy*100:.2f}%)\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(\"-\"*80)\n",
    "print(classification_report(y_test, test_predictions, target_names=['Negative', 'Positive']))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, test_predictions)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cdbb3ff",
   "metadata": {},
   "source": [
    "## 8. Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdffa45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot accuracy comparison\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Accuracy bar chart\n",
    "accuracies = [train_accuracy, test_accuracy]\n",
    "labels = ['Train', 'Test']\n",
    "colors = ['#e74c3c', '#3498db']\n",
    "\n",
    "ax1.bar(labels, accuracies, color=colors, alpha=0.7)\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.set_title('SBERT - Train vs Test Accuracy')\n",
    "ax1.set_ylim([0, 1])\n",
    "ax1.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, (label, acc) in enumerate(zip(labels, accuracies)):\n",
    "    ax1.text(i, acc + 0.02, f'{acc:.4f}', ha='center', fontweight='bold')\n",
    "\n",
    "# Confusion Matrix\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Greens',\n",
    "            xticklabels=['Negative', 'Positive'],\n",
    "            yticklabels=['Negative', 'Positive'],\n",
    "            ax=ax2)\n",
    "ax2.set_title('SBERT - Confusion Matrix')\n",
    "ax2.set_ylabel('True Label')\n",
    "ax2.set_xlabel('Predicted Label')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bf6976",
   "metadata": {},
   "source": [
    "## 9. Embedding Space Visualization (t-SNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5ac779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize embeddings with t-SNE (sample subset for speed)\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Sample for visualization\n",
    "sample_size = 1000\n",
    "indices = np.random.choice(len(test_embeddings), size=min(sample_size, len(test_embeddings)), replace=False)\n",
    "\n",
    "sample_embeddings = test_embeddings[indices]\n",
    "sample_labels = y_test[indices]\n",
    "\n",
    "print(f\"Performing t-SNE on {len(sample_embeddings)} samples...\")\n",
    "print(\"This may take a minute...\")\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n",
    "embeddings_2d = tsne.fit_transform(sample_embeddings)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "scatter = plt.scatter(\n",
    "    embeddings_2d[:, 0],\n",
    "    embeddings_2d[:, 1],\n",
    "    c=sample_labels,\n",
    "    cmap='RdYlGn',\n",
    "    alpha=0.6,\n",
    "    s=20\n",
    ")\n",
    "plt.colorbar(scatter, label='Sentiment (0=Neg, 1=Pos)')\n",
    "plt.title('SBERT Sentence Embeddings Visualization (t-SNE)')\n",
    "plt.xlabel('t-SNE Dimension 1')\n",
    "plt.ylabel('t-SNE Dimension 2')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nt-SNE visualization complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6b7fdc",
   "metadata": {},
   "source": [
    "## 10. Test with Custom Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905f7e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment_sbert(text, model, classifier):\n",
    "    # Generate embedding\n",
    "    embedding = model.encode([text], convert_to_numpy=True)\n",
    "    \n",
    "    # Predict\n",
    "    prediction = classifier.predict(embedding)[0]\n",
    "    probability = classifier.predict_proba(embedding)[0]\n",
    "    confidence = probability[prediction]\n",
    "    \n",
    "    return prediction, confidence\n",
    "\n",
    "# Test reviews\n",
    "test_reviews = [\n",
    "    \"This movie was absolutely fantastic! The acting was superb.\",\n",
    "    \"Terrible waste of time. Poor acting and boring plot.\",\n",
    "    \"It was okay, not great but not terrible either.\",\n",
    "    \"One of the best films I've ever seen!\",\n",
    "    \"Complete garbage. Don't waste your money.\"\n",
    "]\n",
    "\n",
    "print(\"Testing custom reviews with SBERT:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for i, review in enumerate(test_reviews, 1):\n",
    "    prediction, confidence = predict_sentiment_sbert(review, model, classifier)\n",
    "    sentiment = \"Positive ✓\" if prediction == 1 else \"Negative ✗\"\n",
    "    print(f\"{i}. Review: {review}\")\n",
    "    print(f\"   Prediction: {sentiment} (Confidence: {confidence:.2%})\\n\")\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654d1bd5",
   "metadata": {},
   "source": [
    "## 11. Compare Sentence Similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bed4d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Example sentences\n",
    "sentences = [\n",
    "    \"This movie is great and entertaining.\",\n",
    "    \"This film is excellent and fun.\",\n",
    "    \"This movie is terrible and boring.\",\n",
    "    \"The weather is nice today.\"\n",
    "]\n",
    "\n",
    "# Generate embeddings\n",
    "sentence_embeddings = model.encode(sentences)\n",
    "\n",
    "# Calculate similarity matrix\n",
    "similarity_matrix = cosine_similarity(sentence_embeddings)\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(\n",
    "    similarity_matrix,\n",
    "    annot=True,\n",
    "    fmt='.3f',\n",
    "    cmap='YlOrRd',\n",
    "    xticklabels=[f\"S{i+1}\" for i in range(len(sentences))],\n",
    "    yticklabels=[f\"S{i+1}\" for i in range(len(sentences))],\n",
    "    vmin=0,\n",
    "    vmax=1\n",
    ")\n",
    "plt.title('SBERT - Sentence Similarity Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Sentences:\")\n",
    "for i, sent in enumerate(sentences, 1):\n",
    "    print(f\"S{i}: {sent}\")\n",
    "\n",
    "print(\"\\nKey observations:\")\n",
    "print(\"- S1 and S2 (both positive) have high similarity\")\n",
    "print(\"- S1/S2 and S3 (opposite sentiment) have lower similarity\")\n",
    "print(\"- S4 (unrelated) has low similarity with all movie reviews\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae02fc4b",
   "metadata": {},
   "source": [
    "## 12. Save Model and Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867482ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save SBERT model\n",
    "model_save_path = './sbert_sentiment'\n",
    "model.save(model_save_path)\n",
    "\n",
    "# Save classifier\n",
    "classifier_path = './sbert_classifier.pkl'\n",
    "with open(classifier_path, 'wb') as f:\n",
    "    pickle.dump(classifier, f)\n",
    "\n",
    "print(f\"SBERT model saved to: {model_save_path}\")\n",
    "print(f\"Classifier saved to: {classifier_path}\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SBERT Summary:\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Model: {MODEL_NAME}\")\n",
    "print(f\"Embedding dimension: {model.get_sentence_embedding_dimension()}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
    "print(f\"Embedding time: {embedding_time:.2f} seconds ({embedding_time/60:.2f} minutes)\")\n",
    "print(f\"Classifier training time: {training_time:.2f} seconds\")\n",
    "print(f\"Total time: {(embedding_time + training_time):.2f} seconds ({(embedding_time + training_time)/60:.2f} minutes)\")\n",
    "print(f\"Advantages: Fast inference, semantic understanding, sentence-level embeddings\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5311bf19",
   "metadata": {},
   "source": [
    "## 13. Load Model (for future use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f1aef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: How to load the saved model and classifier\n",
    "\"\"\"\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import pickle\n",
    "\n",
    "# Load SBERT model\n",
    "loaded_model = SentenceTransformer('./sbert_sentiment')\n",
    "\n",
    "# Load classifier\n",
    "with open('./sbert_classifier.pkl', 'rb') as f:\n",
    "    loaded_classifier = pickle.load(f)\n",
    "\n",
    "# Use for prediction\n",
    "text = \"This movie is amazing!\"\n",
    "embedding = loaded_model.encode([text])\n",
    "prediction = loaded_classifier.predict(embedding)[0]\n",
    "print(f\"Prediction: {'Positive' if prediction == 1 else 'Negative'}\")\n",
    "\"\"\"\n",
    "\n",
    "print(\"Model loading instructions provided above.\")\n",
    "print(\"\\nSBERT training complete! ✓\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
